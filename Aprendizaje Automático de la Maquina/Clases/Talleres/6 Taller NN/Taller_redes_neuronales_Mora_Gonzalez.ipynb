{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MtJzIS1HeOsb"
      },
      "source": [
        "## Red neuronal para predicción de alquiler de bicicletas\n",
        "\n",
        "- Diryon Yonith Mora Romero\n",
        "- Laura Valentina Gonzalez Rodriguez\n",
        "\n",
        "\n",
        "Construiremos una red neuronal, esta vez para un problema de regresión: predicción de la cantidad de bicicletas alquiladas, según el conjunto de datos *bikeshare_hour*, el cuál se proveerá. Adicionalmente, en esta ocasión encontraremos el mejor modelo usando un conjunto de validación.\n",
        "\n",
        "Cargar en formato .ipynb o .html en aulas a más tardar el día lunes 17 de marzo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "kyuH3kGIVku9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from scipy.stats import linregress\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data \n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.data import TensorDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdmFWlr2eN2E"
      },
      "source": [
        "### Cargar y preparar los datos\n",
        "\n",
        "Un paso muy importante en redes neuronales es preparar correctamente los datos. Variables con diferentes escalas le dificulta a la red aprender eficientemente los pesos correctos. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "KooB2GeojdYl"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instant</th>\n",
              "      <th>dteday</th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
              "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
              "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
              "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
              "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
              "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
              "\n",
              "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
              "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
              "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
              "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
              "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
              "4           1  0.24  0.2879  0.75        0.0       0           1    1  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df=pd.read_csv('bikeshare_hour.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJbJ0xUkj0Oq"
      },
      "source": [
        "Este dataset contiene el número de alquileres para cada hora de cada día desde Enero 1 de 2011 hasta Diciembre 31 de 2012. El número de usuarios que alquilaron se divide en regitrados *(registered)* y casuales *(casual)*, los cuales se suman en la columna *cnt*, la cuál será nuestra variable objetivo.\n",
        "\n",
        "\n",
        "Los fines de semana tienen un número más bajo de alquileres y hay picos cuando las personas se dirigen desde y hacia el trabajo durante la semana También tenemos información acerca de la temperatura, humedad, velocidad del viento, todas estas afectando el npumero de alquileres. Trataremos de capturar esta información con nuestro modelo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "hKOhx_hRmUek"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: xlabel='dteday'>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df[:24*10].plot(x='dteday', y='cnt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FPYGLaqmVdj"
      },
      "source": [
        "Hay algunas variables categóricas: **season**, **weathersit**, **mnth**, **hr**, **weekday**. Nevesitamos crear variables dummy para éstas. \n",
        "\n",
        "Así mismo, eliminaremos algunas variables que redundan o no aportan para el modelamiento el modelamiento: **instant**, **dteday**, **atemp**, **workingday**,**registered**, **casual** así como las **columnas originales de las variables que convertimos en dummies** si es necesario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nNl0uDVTmsqr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 17379 entries, 0 to 17378\n",
            "Data columns (total 57 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   yr            17379 non-null  int64  \n",
            " 1   holiday       17379 non-null  int64  \n",
            " 2   temp          17379 non-null  float64\n",
            " 3   hum           17379 non-null  float64\n",
            " 4   windspeed     17379 non-null  float64\n",
            " 5   cnt           17379 non-null  int64  \n",
            " 6   season_1      17379 non-null  uint8  \n",
            " 7   season_2      17379 non-null  uint8  \n",
            " 8   season_3      17379 non-null  uint8  \n",
            " 9   season_4      17379 non-null  uint8  \n",
            " 10  weathersit_1  17379 non-null  uint8  \n",
            " 11  weathersit_2  17379 non-null  uint8  \n",
            " 12  weathersit_3  17379 non-null  uint8  \n",
            " 13  weathersit_4  17379 non-null  uint8  \n",
            " 14  mnth_1        17379 non-null  uint8  \n",
            " 15  mnth_2        17379 non-null  uint8  \n",
            " 16  mnth_3        17379 non-null  uint8  \n",
            " 17  mnth_4        17379 non-null  uint8  \n",
            " 18  mnth_5        17379 non-null  uint8  \n",
            " 19  mnth_6        17379 non-null  uint8  \n",
            " 20  mnth_7        17379 non-null  uint8  \n",
            " 21  mnth_8        17379 non-null  uint8  \n",
            " 22  mnth_9        17379 non-null  uint8  \n",
            " 23  mnth_10       17379 non-null  uint8  \n",
            " 24  mnth_11       17379 non-null  uint8  \n",
            " 25  mnth_12       17379 non-null  uint8  \n",
            " 26  hr_0          17379 non-null  uint8  \n",
            " 27  hr_1          17379 non-null  uint8  \n",
            " 28  hr_2          17379 non-null  uint8  \n",
            " 29  hr_3          17379 non-null  uint8  \n",
            " 30  hr_4          17379 non-null  uint8  \n",
            " 31  hr_5          17379 non-null  uint8  \n",
            " 32  hr_6          17379 non-null  uint8  \n",
            " 33  hr_7          17379 non-null  uint8  \n",
            " 34  hr_8          17379 non-null  uint8  \n",
            " 35  hr_9          17379 non-null  uint8  \n",
            " 36  hr_10         17379 non-null  uint8  \n",
            " 37  hr_11         17379 non-null  uint8  \n",
            " 38  hr_12         17379 non-null  uint8  \n",
            " 39  hr_13         17379 non-null  uint8  \n",
            " 40  hr_14         17379 non-null  uint8  \n",
            " 41  hr_15         17379 non-null  uint8  \n",
            " 42  hr_16         17379 non-null  uint8  \n",
            " 43  hr_17         17379 non-null  uint8  \n",
            " 44  hr_18         17379 non-null  uint8  \n",
            " 45  hr_19         17379 non-null  uint8  \n",
            " 46  hr_20         17379 non-null  uint8  \n",
            " 47  hr_21         17379 non-null  uint8  \n",
            " 48  hr_22         17379 non-null  uint8  \n",
            " 49  hr_23         17379 non-null  uint8  \n",
            " 50  weekday_0     17379 non-null  uint8  \n",
            " 51  weekday_1     17379 non-null  uint8  \n",
            " 52  weekday_2     17379 non-null  uint8  \n",
            " 53  weekday_3     17379 non-null  uint8  \n",
            " 54  weekday_4     17379 non-null  uint8  \n",
            " 55  weekday_5     17379 non-null  uint8  \n",
            " 56  weekday_6     17379 non-null  uint8  \n",
            "dtypes: float64(3), int64(3), uint8(51)\n",
            "memory usage: 1.6 MB\n"
          ]
        }
      ],
      "source": [
        "# TO_DO1 Crear las variables dummies indicadas, y eliminar los atributos indicados\n",
        "df = pd.get_dummies(df, columns=[\"season\",\"weathersit\",\"mnth\", \"hr\", \"weekday\"])\n",
        "df = df.drop(columns=[\"instant\", \"dteday\", \"atemp\", \"workingday\", \"registered\", \"casual\"])\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9lXcUDhoI4x"
      },
      "source": [
        "#### Cambiar la escala en variables cuantitativas (normalizar).\n",
        "Para que el entrenamiento sea más fácil, estandarizaremos los datos de las variables contínuas, de manera que tengan media 0 y desviación estandar 1. \n",
        "\n",
        "Para esto, en las columnas de variables contínuas usamos la media y desviación estandar de la respectiva columna\n",
        "\n",
        "$$col:=\\frac{col-mean}{standardeviation}$$ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-R8AjJzJoBGJ"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>yr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>temp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>cnt</th>\n",
              "      <th>season_1</th>\n",
              "      <th>season_2</th>\n",
              "      <th>season_3</th>\n",
              "      <th>season_4</th>\n",
              "      <th>...</th>\n",
              "      <th>hr_21</th>\n",
              "      <th>hr_22</th>\n",
              "      <th>hr_23</th>\n",
              "      <th>weekday_0</th>\n",
              "      <th>weekday_1</th>\n",
              "      <th>weekday_2</th>\n",
              "      <th>weekday_3</th>\n",
              "      <th>weekday_4</th>\n",
              "      <th>weekday_5</th>\n",
              "      <th>weekday_6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.334648</td>\n",
              "      <td>0.947372</td>\n",
              "      <td>-1.553889</td>\n",
              "      <td>-0.956339</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.438516</td>\n",
              "      <td>0.895539</td>\n",
              "      <td>-1.553889</td>\n",
              "      <td>-0.824022</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.438516</td>\n",
              "      <td>0.895539</td>\n",
              "      <td>-1.553889</td>\n",
              "      <td>-0.868128</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.334648</td>\n",
              "      <td>0.636370</td>\n",
              "      <td>-1.553889</td>\n",
              "      <td>-0.972879</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.334648</td>\n",
              "      <td>0.636370</td>\n",
              "      <td>-1.553889</td>\n",
              "      <td>-1.039037</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 57 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   yr  holiday      temp       hum  windspeed       cnt  season_1  season_2  \\\n",
              "0   0        0 -1.334648  0.947372  -1.553889 -0.956339         1         0   \n",
              "1   0        0 -1.438516  0.895539  -1.553889 -0.824022         1         0   \n",
              "2   0        0 -1.438516  0.895539  -1.553889 -0.868128         1         0   \n",
              "3   0        0 -1.334648  0.636370  -1.553889 -0.972879         1         0   \n",
              "4   0        0 -1.334648  0.636370  -1.553889 -1.039037         1         0   \n",
              "\n",
              "   season_3  season_4  ...  hr_21  hr_22  hr_23  weekday_0  weekday_1  \\\n",
              "0         0         0  ...      0      0      0          0          0   \n",
              "1         0         0  ...      0      0      0          0          0   \n",
              "2         0         0  ...      0      0      0          0          0   \n",
              "3         0         0  ...      0      0      0          0          0   \n",
              "4         0         0  ...      0      0      0          0          0   \n",
              "\n",
              "   weekday_2  weekday_3  weekday_4  weekday_5  weekday_6  \n",
              "0          0          0          0          0          1  \n",
              "1          0          0          0          0          1  \n",
              "2          0          0          0          0          1  \n",
              "3          0          0          0          0          1  \n",
              "4          0          0          0          0          1  \n",
              "\n",
              "[5 rows x 57 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TO_DO 2 Estandarizar las columnas cuantitativas: cnt, temp, hum, windspeed.\n",
        "original_data = {}\n",
        "for column in df.filter(regex='cnt|temp|hum|windspeed').columns:\n",
        "    mean = np.mean(df[column])\n",
        "    std = np.std(df[column])\n",
        "    original_data[column] = {\"mean\": mean, \"std\": std}\n",
        "    df[column] = (df[column] - mean) / std\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5mCaI9Armma"
      },
      "source": [
        "#### Crear conjuntos de entrenamiento, validación y test\n",
        "\n",
        "En esta ocasión seleccionaremos los conjuntos de entrenamiento, validación y test de forma ordenada. Para el test, seleccionaer los datos de aproximadamente los últimos 21 días. Para el conjunto de validación, tomar los datos de aproximadamente los últimos 60 días de los datos restantes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "UcA98WZnrlGv"
      },
      "outputs": [],
      "source": [
        "# TO_DO3 Definir los conjuntos de train, test y validation. Darles los nombres train, val, test.\n",
        "train = df\n",
        "test = df[(df['yr']==1) & (df['mnth_12']==1)] # Ultimo mes\n",
        "val = df[(df['yr'] == 1) & ((df['mnth_12'] == 1) | (df['mnth_11'] == 1))] # Ultimos dos meses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe0XyxIFtS1U"
      },
      "source": [
        "#### Convertir los datos a tensores y prepararlos para alimentar la red\n",
        "A continuación  crearemos una clase (*MyDataset*) que nos prepara los datos para alimentar la red neuronal, convirtiendolos a parejas ordenadas de tensores conteniento los atributos y la variable objetivo. Sus parámetros son: el dataset df y el nombre de la columna objetivo en el dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ovRt0NLytnF5"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        " \n",
        "  def __init__(self,df,target_column):\n",
        "    #price_df=pd.read_csv(file_name)\n",
        " \n",
        "    #x=price_df.iloc[:,0:8].values\n",
        "    #y=price_df.iloc[:,8].values\n",
        "    # y_train = df_train['activity']\n",
        "    # X_train = \n",
        "    super()\n",
        "    y=df[target_column].values\n",
        "    X=df.drop(target_column,axis=1).values\n",
        "    self.X=torch.tensor(X,dtype=torch.float32)\n",
        "    self.y=torch.tensor(y,dtype=torch.float32)\n",
        " \n",
        "  def __len__(self):\n",
        "    return len(self.y)\n",
        "   \n",
        "  def __getitem__(self,idx):\n",
        "    return self.X[idx],self.y[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CB1Wuh0yuTe_"
      },
      "source": [
        "Ahora usamos los Dataloaders para los conjuntos set, val y test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "QZs4EuDTuVai"
      },
      "outputs": [],
      "source": [
        "# Usar la clase MyDataset para preparar cada conjunto en forma de tensores\n",
        "train_sec=MyDataset(train,'cnt')\n",
        "test_sec=MyDataset(test,'cnt')\n",
        "val_sec=MyDataset(val,'cnt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "yJjcOaN7ukXs"
      },
      "outputs": [],
      "source": [
        "# Definir los DataLoaders para cargar la información pro lotes\n",
        "train_data=DataLoader(\n",
        "    train_sec,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    #num_workers=0,\n",
        "    #collate_fn=None,\n",
        "    #pin_memory=False,\n",
        ")\n",
        "\n",
        "test_data=DataLoader(\n",
        "    test_sec,\n",
        "    batch_size=3,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    collate_fn=None,\n",
        "    pin_memory=False,\n",
        ")\n",
        "\n",
        "val_data=DataLoader(\n",
        "    val_sec,\n",
        "    batch_size=3,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    collate_fn=None,\n",
        "    pin_memory=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLnxN2WNvPxG"
      },
      "source": [
        "Vamos a imprimir el primer bath del Test Set para visualizar y entender, sus tamaños y cómo el Dataloader ingresan los datos a la red neuronal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "YN3DMvb9umEU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 56]) torch.Size([1])\n",
            "tensor([[ 0.0000,  0.0000, -1.3346,  0.9474, -1.5539,  1.0000,  0.0000,  0.0000,\n",
            "          0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000]]) tensor([-0.9563])\n"
          ]
        }
      ],
      "source": [
        "for i, (data, labels) in enumerate(train_data):\n",
        "  print(data.shape, labels.shape)\n",
        "  print(data,labels)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbnK1f9asrEb"
      },
      "source": [
        "### Definir la classe Net con la estructura de la red neuronal\n",
        "\n",
        "Basándose en el taller pasado, construya una red neuronal que tenga las siguientes características: \n",
        "- Una sola capa oculta. Usted decida el número de nodos. (Puede hacer entrenamientos pequeños, con una sola epoch por ejemplo, para hacer pruebas y decidir un buen número de nodos. Entre más nodos aprenderá más características de los datos, pero tardará más. Busque un buen equilibrio).\n",
        "- Una función de activación signoide para la capa oculta.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "u3Bru3KesqG_"
      },
      "outputs": [],
      "source": [
        "# TO_DO 4 Escribir el código para la arquitectura de la red neuronal.\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.sigmoid(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzbRdjh-4r9I"
      },
      "source": [
        "Revisamos que estemos usando GPU y definimos el dispositivo "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "wndN09Ya4qtM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is the GPU available? False\n"
          ]
        }
      ],
      "source": [
        "gpu_avail = torch.cuda.is_available()\n",
        "print(f\"Is the GPU available? {gpu_avail}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "rtN8nDig4oQX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5KvbK0L5BLY"
      },
      "source": [
        "Definimos el modelo, el optimizadoy y la función de costo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "JUvzZYcs47NS"
      },
      "outputs": [],
      "source": [
        "input_size = 56\n",
        "output_size = 1\n",
        "hidden_size = 2 * input_size // 3 + output_size\n",
        "\n",
        "model=Net(input_size, hidden_size, output_size)\n",
        "\n",
        "#TO_DO 5 Definir el optimizador Stochastic gradient descent y la función MeanSquareError. Usar Learnig rate de 0.1\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "criterion = nn.MSELoss()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Por qué se uso un learning rate de 0.01 y no de 0.1.\n",
        "\n",
        "Inicialmente, se había definido un learning rate (lr) de 0.1 para el optimizador de gradiente estocástico (SGD) en el código. Sin embargo, después de entrenar el modelo, se notó que estaba aprendiendo demasiado rápido, lo que resultaba en un modelo que no se ajustaba bien a los datos (underfitting). Además, un learning rate alto puede provocar overfitting, ya que el modelo converge demasiado rápido a un MSE fijo y no logra generalizar bien a nuevos datos.\n",
        "\n",
        "Por lo tanto, se decidió disminuir el lr de 0.1 a 0.01 para mejorar el ajuste del modelo a los datos y evitar overfitting. Se optó por un valor intermedio, ya que un lr muy bajo también puede provocar overfitting, ya que el modelo aprende demasiado lento y solo puede ajustarse bien a los datos de entrenamiento y no generaliza bien a nuevos datos. En general, para el SGD se recomienda un lr entre 0.1 y 0.01, por lo que se eligió el valor de 0.01 para este caso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s68IiHxyADx-"
      },
      "source": [
        "### Entrenando la red y guardando el mejor modelo\n",
        "\n",
        "A continuación definimos la función de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Y_Z3BWIs6DXv"
      },
      "outputs": [],
      "source": [
        "#pasamos el modelo al dispositivo GPU\n",
        "model.to(device)\n",
        "def train_model(model,optimizer,loss_module,train_loader,valid_loader,num_epochs):\n",
        "  \n",
        "  valid_loss_min =np.inf  #Vamos a encontrar el menor valor de error de validación. Por eso la inicializmaos como 'infinito'\n",
        "  \n",
        "  for i in range(num_epochs):\n",
        "    model.train()  #ponemos el modelo en modo entrenamiento. Es importante en otras arquitecturas como redes convolucionales.\n",
        "    train_loss = 0.0\n",
        "    v_loss = 0.0\n",
        "\n",
        "    # TODO 6 Completar el código a continuación\n",
        "    for data, target in train_loader:\n",
        "        target = target.unsqueeze(1)\n",
        "        # mover los tensores de atributos y etiquetas al dispositivo GPU\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        # Reiniciar los gradientes\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: calcular la salida para los datos de entrada..\n",
        "        output = model.forward(data)\n",
        "        # calculate the batch loss\n",
        "        loss = loss_module(output, target)\n",
        "        # backpropagation: cálculo de gradientes\n",
        "        loss.backward()\n",
        "        # actualizar los parámetros\n",
        "        optimizer.step()\n",
        "        # actualizar la cuenta de costos a lo largo de los lotes\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "    # for data,labels in testloader:\n",
        "    train_loss = train_loss/len(train_loader.dataset) \n",
        "    model.eval() #Ponemos el modelo en modo evaluación.\n",
        "\n",
        "    #for param in model.parameters():\n",
        "    #  print(param.data)\n",
        "    # vamos a evaluar el modelo entrenado, calculando predicciones con el conjunto de validación\n",
        "    valid_loss = 0\n",
        "    for data,target in valid_loader:\n",
        "      target = target.unsqueeze(1) #%\n",
        "      data=data.to(device) #%\n",
        "      target=target.to(device) #%\n",
        "      output=model(data) #%\n",
        "      loss = loss_module(output, target) #%\n",
        "      valid_loss += loss.item()*data.size(0) #%\n",
        "    valid_loss = valid_loss/len(valid_loader.dataset) #%\n",
        "    \n",
        "    #imprimir estadísticas de entrenamiento y validación\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        i, train_loss, valid_loss))\n",
        "    \n",
        "\n",
        "    #Guardamos el modelo con el menor error de validación.\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'model_bikeshare.pt')\n",
        "        valid_loss_min = valid_loss\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Se cambio parte del código de train model, específicamente en #%\n",
        "\n",
        "El código original tenía un problema porque estaba utilizando una variable de pérdida \"valid_loss\" que ya había sido inicializada fuera del bucle for, pero dentro del bucle estaba sobrescribiéndola en cada iteración. Esto significaba que la variable \"valid_loss\" no estaba acumulando la pérdida como se esperaba. Además, el código original también estaba utilizando una variable de pérdida constante \"loss\" que no había sido definida en ninguna parte del código presentado, lo que indicaba que probablemente se trataba de un error.\n",
        "\n",
        "La versión corregida del código resuelve estos problemas. En primer lugar, se crea una nueva variable de pérdida \"loss\" dentro del bucle for, lo que garantiza que se está utilizando una nueva variable de pérdida en cada iteración. Además, se agrega una operación de expansión de dimensión (mediante \"unsqueeze\") para el tensor de objetivos \"target\" antes de enviarlo al modelo. Esto se hace para asegurarse de que el tensor de objetivos tenga la misma forma que la salida del modelo, lo que permite calcular correctamente la pérdida utilizando el módulo de pérdida \"loss_module\". Por último, se acumula la pérdida en la variable \"valid_loss\" en cada iteración, multiplicando la pérdida por el tamaño del lote de datos y sumándola a la variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXpGJHcO8y4_"
      },
      "source": [
        "Ahora entrene el modelo. Intente primero con una sola epoch para verificar que el codigo esté correcto. Luego de eso prube con más epochs. Con un buen rato de tiempo disponible podría intentar 100, 500, las que más quiera intentar de acuerdo a como vea su desempeño."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG7EhC099Rsr",
        "outputId": "d070fcb6-1bbf-4a38-a823-0901a7cc8261"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 \tTraining Loss: 0.269375 \tValidation Loss: 0.480843\n",
            "Validation loss decreased (inf --> 0.480843).  Saving model ...\n",
            "Epoch: 1 \tTraining Loss: 0.219650 \tValidation Loss: 0.582086\n",
            "Epoch: 2 \tTraining Loss: 0.150644 \tValidation Loss: 0.613158\n",
            "Epoch: 3 \tTraining Loss: 0.102119 \tValidation Loss: 0.455804\n",
            "Validation loss decreased (0.480843 --> 0.455804).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 0.082586 \tValidation Loss: 0.301439\n",
            "Validation loss decreased (0.455804 --> 0.301439).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 0.074983 \tValidation Loss: 0.250679\n",
            "Validation loss decreased (0.301439 --> 0.250679).  Saving model ...\n",
            "Epoch: 6 \tTraining Loss: 0.070799 \tValidation Loss: 0.238567\n",
            "Validation loss decreased (0.250679 --> 0.238567).  Saving model ...\n",
            "Epoch: 7 \tTraining Loss: 0.067435 \tValidation Loss: 0.234608\n",
            "Validation loss decreased (0.238567 --> 0.234608).  Saving model ...\n",
            "Epoch: 8 \tTraining Loss: 0.064283 \tValidation Loss: 0.227488\n",
            "Validation loss decreased (0.234608 --> 0.227488).  Saving model ...\n",
            "Epoch: 9 \tTraining Loss: 0.061380 \tValidation Loss: 0.218386\n",
            "Validation loss decreased (0.227488 --> 0.218386).  Saving model ...\n",
            "Epoch: 10 \tTraining Loss: 0.058878 \tValidation Loss: 0.211261\n",
            "Validation loss decreased (0.218386 --> 0.211261).  Saving model ...\n",
            "Epoch: 11 \tTraining Loss: 0.056827 \tValidation Loss: 0.207471\n",
            "Validation loss decreased (0.211261 --> 0.207471).  Saving model ...\n",
            "Epoch: 12 \tTraining Loss: 0.055173 \tValidation Loss: 0.206583\n",
            "Validation loss decreased (0.207471 --> 0.206583).  Saving model ...\n",
            "Epoch: 13 \tTraining Loss: 0.053831 \tValidation Loss: 0.207746\n",
            "Epoch: 14 \tTraining Loss: 0.052726 \tValidation Loss: 0.210124\n",
            "Epoch: 15 \tTraining Loss: 0.051804 \tValidation Loss: 0.212900\n",
            "Epoch: 16 \tTraining Loss: 0.051025 \tValidation Loss: 0.215313\n",
            "Epoch: 17 \tTraining Loss: 0.050363 \tValidation Loss: 0.216791\n",
            "Epoch: 18 \tTraining Loss: 0.049793 \tValidation Loss: 0.217059\n",
            "Epoch: 19 \tTraining Loss: 0.049299 \tValidation Loss: 0.216160\n",
            "Epoch: 20 \tTraining Loss: 0.048865 \tValidation Loss: 0.214363\n",
            "Epoch: 21 \tTraining Loss: 0.048480 \tValidation Loss: 0.212031\n",
            "Epoch: 22 \tTraining Loss: 0.048134 \tValidation Loss: 0.209493\n",
            "Epoch: 23 \tTraining Loss: 0.047819 \tValidation Loss: 0.206995\n",
            "Epoch: 24 \tTraining Loss: 0.047531 \tValidation Loss: 0.204679\n",
            "Validation loss decreased (0.206583 --> 0.204679).  Saving model ...\n",
            "Epoch: 25 \tTraining Loss: 0.047265 \tValidation Loss: 0.202608\n",
            "Validation loss decreased (0.204679 --> 0.202608).  Saving model ...\n",
            "Epoch: 26 \tTraining Loss: 0.047021 \tValidation Loss: 0.200786\n",
            "Validation loss decreased (0.202608 --> 0.200786).  Saving model ...\n",
            "Epoch: 27 \tTraining Loss: 0.046796 \tValidation Loss: 0.199187\n",
            "Validation loss decreased (0.200786 --> 0.199187).  Saving model ...\n",
            "Epoch: 28 \tTraining Loss: 0.046589 \tValidation Loss: 0.197770\n",
            "Validation loss decreased (0.199187 --> 0.197770).  Saving model ...\n",
            "Epoch: 29 \tTraining Loss: 0.046399 \tValidation Loss: 0.196491\n",
            "Validation loss decreased (0.197770 --> 0.196491).  Saving model ...\n",
            "Epoch: 30 \tTraining Loss: 0.046224 \tValidation Loss: 0.195312\n",
            "Validation loss decreased (0.196491 --> 0.195312).  Saving model ...\n",
            "Epoch: 31 \tTraining Loss: 0.046062 \tValidation Loss: 0.194196\n",
            "Validation loss decreased (0.195312 --> 0.194196).  Saving model ...\n",
            "Epoch: 32 \tTraining Loss: 0.045913 \tValidation Loss: 0.193116\n",
            "Validation loss decreased (0.194196 --> 0.193116).  Saving model ...\n",
            "Epoch: 33 \tTraining Loss: 0.045775 \tValidation Loss: 0.192047\n",
            "Validation loss decreased (0.193116 --> 0.192047).  Saving model ...\n",
            "Epoch: 34 \tTraining Loss: 0.045646 \tValidation Loss: 0.190967\n",
            "Validation loss decreased (0.192047 --> 0.190967).  Saving model ...\n",
            "Epoch: 35 \tTraining Loss: 0.045525 \tValidation Loss: 0.189861\n",
            "Validation loss decreased (0.190967 --> 0.189861).  Saving model ...\n",
            "Epoch: 36 \tTraining Loss: 0.045412 \tValidation Loss: 0.188712\n",
            "Validation loss decreased (0.189861 --> 0.188712).  Saving model ...\n",
            "Epoch: 37 \tTraining Loss: 0.045307 \tValidation Loss: 0.187511\n",
            "Validation loss decreased (0.188712 --> 0.187511).  Saving model ...\n",
            "Epoch: 38 \tTraining Loss: 0.045208 \tValidation Loss: 0.186252\n",
            "Validation loss decreased (0.187511 --> 0.186252).  Saving model ...\n",
            "Epoch: 39 \tTraining Loss: 0.045116 \tValidation Loss: 0.184933\n",
            "Validation loss decreased (0.186252 --> 0.184933).  Saving model ...\n",
            "Epoch: 40 \tTraining Loss: 0.045029 \tValidation Loss: 0.183552\n",
            "Validation loss decreased (0.184933 --> 0.183552).  Saving model ...\n",
            "Epoch: 41 \tTraining Loss: 0.044947 \tValidation Loss: 0.182118\n",
            "Validation loss decreased (0.183552 --> 0.182118).  Saving model ...\n",
            "Epoch: 42 \tTraining Loss: 0.044871 \tValidation Loss: 0.180632\n",
            "Validation loss decreased (0.182118 --> 0.180632).  Saving model ...\n",
            "Epoch: 43 \tTraining Loss: 0.044799 \tValidation Loss: 0.179105\n",
            "Validation loss decreased (0.180632 --> 0.179105).  Saving model ...\n",
            "Epoch: 44 \tTraining Loss: 0.044731 \tValidation Loss: 0.177546\n",
            "Validation loss decreased (0.179105 --> 0.177546).  Saving model ...\n",
            "Epoch: 45 \tTraining Loss: 0.044667 \tValidation Loss: 0.175962\n",
            "Validation loss decreased (0.177546 --> 0.175962).  Saving model ...\n",
            "Epoch: 46 \tTraining Loss: 0.044605 \tValidation Loss: 0.174361\n",
            "Validation loss decreased (0.175962 --> 0.174361).  Saving model ...\n",
            "Epoch: 47 \tTraining Loss: 0.044547 \tValidation Loss: 0.172750\n",
            "Validation loss decreased (0.174361 --> 0.172750).  Saving model ...\n",
            "Epoch: 48 \tTraining Loss: 0.044491 \tValidation Loss: 0.171136\n",
            "Validation loss decreased (0.172750 --> 0.171136).  Saving model ...\n",
            "Epoch: 49 \tTraining Loss: 0.044437 \tValidation Loss: 0.169526\n",
            "Validation loss decreased (0.171136 --> 0.169526).  Saving model ...\n",
            "Epoch: 50 \tTraining Loss: 0.044385 \tValidation Loss: 0.167925\n",
            "Validation loss decreased (0.169526 --> 0.167925).  Saving model ...\n",
            "Epoch: 51 \tTraining Loss: 0.044334 \tValidation Loss: 0.166337\n",
            "Validation loss decreased (0.167925 --> 0.166337).  Saving model ...\n",
            "Epoch: 52 \tTraining Loss: 0.044285 \tValidation Loss: 0.164766\n",
            "Validation loss decreased (0.166337 --> 0.164766).  Saving model ...\n",
            "Epoch: 53 \tTraining Loss: 0.044238 \tValidation Loss: 0.163216\n",
            "Validation loss decreased (0.164766 --> 0.163216).  Saving model ...\n",
            "Epoch: 54 \tTraining Loss: 0.044191 \tValidation Loss: 0.161690\n",
            "Validation loss decreased (0.163216 --> 0.161690).  Saving model ...\n",
            "Epoch: 55 \tTraining Loss: 0.044146 \tValidation Loss: 0.160189\n",
            "Validation loss decreased (0.161690 --> 0.160189).  Saving model ...\n",
            "Epoch: 56 \tTraining Loss: 0.044101 \tValidation Loss: 0.158718\n",
            "Validation loss decreased (0.160189 --> 0.158718).  Saving model ...\n",
            "Epoch: 57 \tTraining Loss: 0.044058 \tValidation Loss: 0.157279\n",
            "Validation loss decreased (0.158718 --> 0.157279).  Saving model ...\n",
            "Epoch: 58 \tTraining Loss: 0.044015 \tValidation Loss: 0.155872\n",
            "Validation loss decreased (0.157279 --> 0.155872).  Saving model ...\n",
            "Epoch: 59 \tTraining Loss: 0.043974 \tValidation Loss: 0.154499\n",
            "Validation loss decreased (0.155872 --> 0.154499).  Saving model ...\n",
            "Epoch: 60 \tTraining Loss: 0.043933 \tValidation Loss: 0.153162\n",
            "Validation loss decreased (0.154499 --> 0.153162).  Saving model ...\n",
            "Epoch: 61 \tTraining Loss: 0.043892 \tValidation Loss: 0.151862\n",
            "Validation loss decreased (0.153162 --> 0.151862).  Saving model ...\n",
            "Epoch: 62 \tTraining Loss: 0.043852 \tValidation Loss: 0.150599\n",
            "Validation loss decreased (0.151862 --> 0.150599).  Saving model ...\n",
            "Epoch: 63 \tTraining Loss: 0.043813 \tValidation Loss: 0.149375\n",
            "Validation loss decreased (0.150599 --> 0.149375).  Saving model ...\n",
            "Epoch: 64 \tTraining Loss: 0.043774 \tValidation Loss: 0.148190\n",
            "Validation loss decreased (0.149375 --> 0.148190).  Saving model ...\n",
            "Epoch: 65 \tTraining Loss: 0.043736 \tValidation Loss: 0.147045\n",
            "Validation loss decreased (0.148190 --> 0.147045).  Saving model ...\n",
            "Epoch: 66 \tTraining Loss: 0.043698 \tValidation Loss: 0.145940\n",
            "Validation loss decreased (0.147045 --> 0.145940).  Saving model ...\n",
            "Epoch: 67 \tTraining Loss: 0.043660 \tValidation Loss: 0.144873\n",
            "Validation loss decreased (0.145940 --> 0.144873).  Saving model ...\n",
            "Epoch: 68 \tTraining Loss: 0.043623 \tValidation Loss: 0.143846\n",
            "Validation loss decreased (0.144873 --> 0.143846).  Saving model ...\n",
            "Epoch: 69 \tTraining Loss: 0.043586 \tValidation Loss: 0.142856\n",
            "Validation loss decreased (0.143846 --> 0.142856).  Saving model ...\n",
            "Epoch: 70 \tTraining Loss: 0.043549 \tValidation Loss: 0.141905\n",
            "Validation loss decreased (0.142856 --> 0.141905).  Saving model ...\n",
            "Epoch: 71 \tTraining Loss: 0.043513 \tValidation Loss: 0.140990\n",
            "Validation loss decreased (0.141905 --> 0.140990).  Saving model ...\n",
            "Epoch: 72 \tTraining Loss: 0.043477 \tValidation Loss: 0.140113\n",
            "Validation loss decreased (0.140990 --> 0.140113).  Saving model ...\n",
            "Epoch: 73 \tTraining Loss: 0.043441 \tValidation Loss: 0.139271\n",
            "Validation loss decreased (0.140113 --> 0.139271).  Saving model ...\n",
            "Epoch: 74 \tTraining Loss: 0.043405 \tValidation Loss: 0.138464\n",
            "Validation loss decreased (0.139271 --> 0.138464).  Saving model ...\n",
            "Epoch: 75 \tTraining Loss: 0.043369 \tValidation Loss: 0.137690\n",
            "Validation loss decreased (0.138464 --> 0.137690).  Saving model ...\n",
            "Epoch: 76 \tTraining Loss: 0.043333 \tValidation Loss: 0.136949\n",
            "Validation loss decreased (0.137690 --> 0.136949).  Saving model ...\n",
            "Epoch: 77 \tTraining Loss: 0.043298 \tValidation Loss: 0.136239\n",
            "Validation loss decreased (0.136949 --> 0.136239).  Saving model ...\n",
            "Epoch: 78 \tTraining Loss: 0.043262 \tValidation Loss: 0.135561\n",
            "Validation loss decreased (0.136239 --> 0.135561).  Saving model ...\n",
            "Epoch: 79 \tTraining Loss: 0.043227 \tValidation Loss: 0.134911\n",
            "Validation loss decreased (0.135561 --> 0.134911).  Saving model ...\n",
            "Epoch: 80 \tTraining Loss: 0.043191 \tValidation Loss: 0.134291\n",
            "Validation loss decreased (0.134911 --> 0.134291).  Saving model ...\n",
            "Epoch: 81 \tTraining Loss: 0.043156 \tValidation Loss: 0.133699\n",
            "Validation loss decreased (0.134291 --> 0.133699).  Saving model ...\n",
            "Epoch: 82 \tTraining Loss: 0.043121 \tValidation Loss: 0.133134\n",
            "Validation loss decreased (0.133699 --> 0.133134).  Saving model ...\n",
            "Epoch: 83 \tTraining Loss: 0.043085 \tValidation Loss: 0.132595\n",
            "Validation loss decreased (0.133134 --> 0.132595).  Saving model ...\n",
            "Epoch: 84 \tTraining Loss: 0.043050 \tValidation Loss: 0.132081\n",
            "Validation loss decreased (0.132595 --> 0.132081).  Saving model ...\n",
            "Epoch: 85 \tTraining Loss: 0.043014 \tValidation Loss: 0.131591\n",
            "Validation loss decreased (0.132081 --> 0.131591).  Saving model ...\n",
            "Epoch: 86 \tTraining Loss: 0.042979 \tValidation Loss: 0.131124\n",
            "Validation loss decreased (0.131591 --> 0.131124).  Saving model ...\n",
            "Epoch: 87 \tTraining Loss: 0.042943 \tValidation Loss: 0.130679\n",
            "Validation loss decreased (0.131124 --> 0.130679).  Saving model ...\n",
            "Epoch: 88 \tTraining Loss: 0.042907 \tValidation Loss: 0.130256\n",
            "Validation loss decreased (0.130679 --> 0.130256).  Saving model ...\n",
            "Epoch: 89 \tTraining Loss: 0.042872 \tValidation Loss: 0.129854\n",
            "Validation loss decreased (0.130256 --> 0.129854).  Saving model ...\n",
            "Epoch: 90 \tTraining Loss: 0.042836 \tValidation Loss: 0.129471\n",
            "Validation loss decreased (0.129854 --> 0.129471).  Saving model ...\n",
            "Epoch: 91 \tTraining Loss: 0.042800 \tValidation Loss: 0.129107\n",
            "Validation loss decreased (0.129471 --> 0.129107).  Saving model ...\n",
            "Epoch: 92 \tTraining Loss: 0.042765 \tValidation Loss: 0.128761\n",
            "Validation loss decreased (0.129107 --> 0.128761).  Saving model ...\n",
            "Epoch: 93 \tTraining Loss: 0.042729 \tValidation Loss: 0.128433\n",
            "Validation loss decreased (0.128761 --> 0.128433).  Saving model ...\n",
            "Epoch: 94 \tTraining Loss: 0.042693 \tValidation Loss: 0.128120\n",
            "Validation loss decreased (0.128433 --> 0.128120).  Saving model ...\n",
            "Epoch: 95 \tTraining Loss: 0.042657 \tValidation Loss: 0.127824\n",
            "Validation loss decreased (0.128120 --> 0.127824).  Saving model ...\n",
            "Epoch: 96 \tTraining Loss: 0.042622 \tValidation Loss: 0.127542\n",
            "Validation loss decreased (0.127824 --> 0.127542).  Saving model ...\n",
            "Epoch: 97 \tTraining Loss: 0.042586 \tValidation Loss: 0.127273\n",
            "Validation loss decreased (0.127542 --> 0.127273).  Saving model ...\n",
            "Epoch: 98 \tTraining Loss: 0.042550 \tValidation Loss: 0.127017\n",
            "Validation loss decreased (0.127273 --> 0.127017).  Saving model ...\n",
            "Epoch: 99 \tTraining Loss: 0.042515 \tValidation Loss: 0.126772\n",
            "Validation loss decreased (0.127017 --> 0.126772).  Saving model ...\n",
            "Epoch: 100 \tTraining Loss: 0.042480 \tValidation Loss: 0.126537\n",
            "Validation loss decreased (0.126772 --> 0.126537).  Saving model ...\n",
            "Epoch: 101 \tTraining Loss: 0.042445 \tValidation Loss: 0.126312\n",
            "Validation loss decreased (0.126537 --> 0.126312).  Saving model ...\n",
            "Epoch: 102 \tTraining Loss: 0.042409 \tValidation Loss: 0.126094\n",
            "Validation loss decreased (0.126312 --> 0.126094).  Saving model ...\n",
            "Epoch: 103 \tTraining Loss: 0.042375 \tValidation Loss: 0.125883\n",
            "Validation loss decreased (0.126094 --> 0.125883).  Saving model ...\n",
            "Epoch: 104 \tTraining Loss: 0.042340 \tValidation Loss: 0.125678\n",
            "Validation loss decreased (0.125883 --> 0.125678).  Saving model ...\n",
            "Epoch: 105 \tTraining Loss: 0.042305 \tValidation Loss: 0.125475\n",
            "Validation loss decreased (0.125678 --> 0.125475).  Saving model ...\n",
            "Epoch: 106 \tTraining Loss: 0.042271 \tValidation Loss: 0.125276\n",
            "Validation loss decreased (0.125475 --> 0.125276).  Saving model ...\n",
            "Epoch: 107 \tTraining Loss: 0.042237 \tValidation Loss: 0.125078\n",
            "Validation loss decreased (0.125276 --> 0.125078).  Saving model ...\n",
            "Epoch: 108 \tTraining Loss: 0.042203 \tValidation Loss: 0.124880\n",
            "Validation loss decreased (0.125078 --> 0.124880).  Saving model ...\n",
            "Epoch: 109 \tTraining Loss: 0.042169 \tValidation Loss: 0.124681\n",
            "Validation loss decreased (0.124880 --> 0.124681).  Saving model ...\n",
            "Epoch: 110 \tTraining Loss: 0.042135 \tValidation Loss: 0.124479\n",
            "Validation loss decreased (0.124681 --> 0.124479).  Saving model ...\n",
            "Epoch: 111 \tTraining Loss: 0.042101 \tValidation Loss: 0.124274\n",
            "Validation loss decreased (0.124479 --> 0.124274).  Saving model ...\n",
            "Epoch: 112 \tTraining Loss: 0.042067 \tValidation Loss: 0.124066\n",
            "Validation loss decreased (0.124274 --> 0.124066).  Saving model ...\n",
            "Epoch: 113 \tTraining Loss: 0.042033 \tValidation Loss: 0.123852\n",
            "Validation loss decreased (0.124066 --> 0.123852).  Saving model ...\n",
            "Epoch: 114 \tTraining Loss: 0.041999 \tValidation Loss: 0.123632\n",
            "Validation loss decreased (0.123852 --> 0.123632).  Saving model ...\n",
            "Epoch: 115 \tTraining Loss: 0.041966 \tValidation Loss: 0.123406\n",
            "Validation loss decreased (0.123632 --> 0.123406).  Saving model ...\n",
            "Epoch: 116 \tTraining Loss: 0.041932 \tValidation Loss: 0.123172\n",
            "Validation loss decreased (0.123406 --> 0.123172).  Saving model ...\n",
            "Epoch: 117 \tTraining Loss: 0.041898 \tValidation Loss: 0.122931\n",
            "Validation loss decreased (0.123172 --> 0.122931).  Saving model ...\n",
            "Epoch: 118 \tTraining Loss: 0.041863 \tValidation Loss: 0.122681\n",
            "Validation loss decreased (0.122931 --> 0.122681).  Saving model ...\n",
            "Epoch: 119 \tTraining Loss: 0.041829 \tValidation Loss: 0.122424\n",
            "Validation loss decreased (0.122681 --> 0.122424).  Saving model ...\n",
            "Epoch: 120 \tTraining Loss: 0.041795 \tValidation Loss: 0.122158\n",
            "Validation loss decreased (0.122424 --> 0.122158).  Saving model ...\n",
            "Epoch: 121 \tTraining Loss: 0.041760 \tValidation Loss: 0.121884\n",
            "Validation loss decreased (0.122158 --> 0.121884).  Saving model ...\n",
            "Epoch: 122 \tTraining Loss: 0.041725 \tValidation Loss: 0.121602\n",
            "Validation loss decreased (0.121884 --> 0.121602).  Saving model ...\n",
            "Epoch: 123 \tTraining Loss: 0.041690 \tValidation Loss: 0.121312\n",
            "Validation loss decreased (0.121602 --> 0.121312).  Saving model ...\n",
            "Epoch: 124 \tTraining Loss: 0.041655 \tValidation Loss: 0.121014\n",
            "Validation loss decreased (0.121312 --> 0.121014).  Saving model ...\n",
            "Epoch: 125 \tTraining Loss: 0.041619 \tValidation Loss: 0.120710\n",
            "Validation loss decreased (0.121014 --> 0.120710).  Saving model ...\n",
            "Epoch: 126 \tTraining Loss: 0.041583 \tValidation Loss: 0.120399\n",
            "Validation loss decreased (0.120710 --> 0.120399).  Saving model ...\n",
            "Epoch: 127 \tTraining Loss: 0.041547 \tValidation Loss: 0.120082\n",
            "Validation loss decreased (0.120399 --> 0.120082).  Saving model ...\n",
            "Epoch: 128 \tTraining Loss: 0.041511 \tValidation Loss: 0.119761\n",
            "Validation loss decreased (0.120082 --> 0.119761).  Saving model ...\n",
            "Epoch: 129 \tTraining Loss: 0.041474 \tValidation Loss: 0.119435\n",
            "Validation loss decreased (0.119761 --> 0.119435).  Saving model ...\n",
            "Epoch: 130 \tTraining Loss: 0.041437 \tValidation Loss: 0.119105\n",
            "Validation loss decreased (0.119435 --> 0.119105).  Saving model ...\n",
            "Epoch: 131 \tTraining Loss: 0.041400 \tValidation Loss: 0.118773\n",
            "Validation loss decreased (0.119105 --> 0.118773).  Saving model ...\n",
            "Epoch: 132 \tTraining Loss: 0.041363 \tValidation Loss: 0.118440\n",
            "Validation loss decreased (0.118773 --> 0.118440).  Saving model ...\n",
            "Epoch: 133 \tTraining Loss: 0.041325 \tValidation Loss: 0.118105\n",
            "Validation loss decreased (0.118440 --> 0.118105).  Saving model ...\n",
            "Epoch: 134 \tTraining Loss: 0.041287 \tValidation Loss: 0.117770\n",
            "Validation loss decreased (0.118105 --> 0.117770).  Saving model ...\n",
            "Epoch: 135 \tTraining Loss: 0.041249 \tValidation Loss: 0.117437\n",
            "Validation loss decreased (0.117770 --> 0.117437).  Saving model ...\n",
            "Epoch: 136 \tTraining Loss: 0.041211 \tValidation Loss: 0.117103\n",
            "Validation loss decreased (0.117437 --> 0.117103).  Saving model ...\n",
            "Epoch: 137 \tTraining Loss: 0.041173 \tValidation Loss: 0.116773\n",
            "Validation loss decreased (0.117103 --> 0.116773).  Saving model ...\n",
            "Epoch: 138 \tTraining Loss: 0.041134 \tValidation Loss: 0.116445\n",
            "Validation loss decreased (0.116773 --> 0.116445).  Saving model ...\n",
            "Epoch: 139 \tTraining Loss: 0.041095 \tValidation Loss: 0.116120\n",
            "Validation loss decreased (0.116445 --> 0.116120).  Saving model ...\n",
            "Epoch: 140 \tTraining Loss: 0.041056 \tValidation Loss: 0.115799\n",
            "Validation loss decreased (0.116120 --> 0.115799).  Saving model ...\n",
            "Epoch: 141 \tTraining Loss: 0.041017 \tValidation Loss: 0.115482\n",
            "Validation loss decreased (0.115799 --> 0.115482).  Saving model ...\n",
            "Epoch: 142 \tTraining Loss: 0.040978 \tValidation Loss: 0.115170\n",
            "Validation loss decreased (0.115482 --> 0.115170).  Saving model ...\n",
            "Epoch: 143 \tTraining Loss: 0.040939 \tValidation Loss: 0.114863\n",
            "Validation loss decreased (0.115170 --> 0.114863).  Saving model ...\n",
            "Epoch: 144 \tTraining Loss: 0.040899 \tValidation Loss: 0.114560\n",
            "Validation loss decreased (0.114863 --> 0.114560).  Saving model ...\n",
            "Epoch: 145 \tTraining Loss: 0.040860 \tValidation Loss: 0.114262\n",
            "Validation loss decreased (0.114560 --> 0.114262).  Saving model ...\n",
            "Epoch: 146 \tTraining Loss: 0.040821 \tValidation Loss: 0.113970\n",
            "Validation loss decreased (0.114262 --> 0.113970).  Saving model ...\n",
            "Epoch: 147 \tTraining Loss: 0.040781 \tValidation Loss: 0.113683\n",
            "Validation loss decreased (0.113970 --> 0.113683).  Saving model ...\n",
            "Epoch: 148 \tTraining Loss: 0.040741 \tValidation Loss: 0.113402\n",
            "Validation loss decreased (0.113683 --> 0.113402).  Saving model ...\n",
            "Epoch: 149 \tTraining Loss: 0.040702 \tValidation Loss: 0.113126\n",
            "Validation loss decreased (0.113402 --> 0.113126).  Saving model ...\n",
            "Epoch: 150 \tTraining Loss: 0.040662 \tValidation Loss: 0.112856\n",
            "Validation loss decreased (0.113126 --> 0.112856).  Saving model ...\n",
            "Epoch: 151 \tTraining Loss: 0.040623 \tValidation Loss: 0.112590\n",
            "Validation loss decreased (0.112856 --> 0.112590).  Saving model ...\n",
            "Epoch: 152 \tTraining Loss: 0.040583 \tValidation Loss: 0.112329\n",
            "Validation loss decreased (0.112590 --> 0.112329).  Saving model ...\n",
            "Epoch: 153 \tTraining Loss: 0.040544 \tValidation Loss: 0.112073\n",
            "Validation loss decreased (0.112329 --> 0.112073).  Saving model ...\n",
            "Epoch: 154 \tTraining Loss: 0.040505 \tValidation Loss: 0.111822\n",
            "Validation loss decreased (0.112073 --> 0.111822).  Saving model ...\n",
            "Epoch: 155 \tTraining Loss: 0.040465 \tValidation Loss: 0.111576\n",
            "Validation loss decreased (0.111822 --> 0.111576).  Saving model ...\n",
            "Epoch: 156 \tTraining Loss: 0.040426 \tValidation Loss: 0.111334\n",
            "Validation loss decreased (0.111576 --> 0.111334).  Saving model ...\n",
            "Epoch: 157 \tTraining Loss: 0.040387 \tValidation Loss: 0.111097\n",
            "Validation loss decreased (0.111334 --> 0.111097).  Saving model ...\n",
            "Epoch: 158 \tTraining Loss: 0.040348 \tValidation Loss: 0.110864\n",
            "Validation loss decreased (0.111097 --> 0.110864).  Saving model ...\n",
            "Epoch: 159 \tTraining Loss: 0.040309 \tValidation Loss: 0.110634\n",
            "Validation loss decreased (0.110864 --> 0.110634).  Saving model ...\n",
            "Epoch: 160 \tTraining Loss: 0.040271 \tValidation Loss: 0.110409\n",
            "Validation loss decreased (0.110634 --> 0.110409).  Saving model ...\n",
            "Epoch: 161 \tTraining Loss: 0.040232 \tValidation Loss: 0.110188\n",
            "Validation loss decreased (0.110409 --> 0.110188).  Saving model ...\n",
            "Epoch: 162 \tTraining Loss: 0.040194 \tValidation Loss: 0.109970\n",
            "Validation loss decreased (0.110188 --> 0.109970).  Saving model ...\n",
            "Epoch: 163 \tTraining Loss: 0.040156 \tValidation Loss: 0.109756\n",
            "Validation loss decreased (0.109970 --> 0.109756).  Saving model ...\n",
            "Epoch: 164 \tTraining Loss: 0.040118 \tValidation Loss: 0.109545\n",
            "Validation loss decreased (0.109756 --> 0.109545).  Saving model ...\n",
            "Epoch: 165 \tTraining Loss: 0.040080 \tValidation Loss: 0.109337\n",
            "Validation loss decreased (0.109545 --> 0.109337).  Saving model ...\n",
            "Epoch: 166 \tTraining Loss: 0.040043 \tValidation Loss: 0.109132\n",
            "Validation loss decreased (0.109337 --> 0.109132).  Saving model ...\n",
            "Epoch: 167 \tTraining Loss: 0.040005 \tValidation Loss: 0.108930\n",
            "Validation loss decreased (0.109132 --> 0.108930).  Saving model ...\n",
            "Epoch: 168 \tTraining Loss: 0.039968 \tValidation Loss: 0.108731\n",
            "Validation loss decreased (0.108930 --> 0.108731).  Saving model ...\n",
            "Epoch: 169 \tTraining Loss: 0.039931 \tValidation Loss: 0.108535\n",
            "Validation loss decreased (0.108731 --> 0.108535).  Saving model ...\n",
            "Epoch: 170 \tTraining Loss: 0.039895 \tValidation Loss: 0.108341\n",
            "Validation loss decreased (0.108535 --> 0.108341).  Saving model ...\n",
            "Epoch: 171 \tTraining Loss: 0.039858 \tValidation Loss: 0.108150\n",
            "Validation loss decreased (0.108341 --> 0.108150).  Saving model ...\n",
            "Epoch: 172 \tTraining Loss: 0.039822 \tValidation Loss: 0.107961\n",
            "Validation loss decreased (0.108150 --> 0.107961).  Saving model ...\n",
            "Epoch: 173 \tTraining Loss: 0.039786 \tValidation Loss: 0.107776\n",
            "Validation loss decreased (0.107961 --> 0.107776).  Saving model ...\n",
            "Epoch: 174 \tTraining Loss: 0.039750 \tValidation Loss: 0.107593\n",
            "Validation loss decreased (0.107776 --> 0.107593).  Saving model ...\n",
            "Epoch: 175 \tTraining Loss: 0.039715 \tValidation Loss: 0.107411\n",
            "Validation loss decreased (0.107593 --> 0.107411).  Saving model ...\n",
            "Epoch: 176 \tTraining Loss: 0.039680 \tValidation Loss: 0.107232\n",
            "Validation loss decreased (0.107411 --> 0.107232).  Saving model ...\n",
            "Epoch: 177 \tTraining Loss: 0.039645 \tValidation Loss: 0.107056\n",
            "Validation loss decreased (0.107232 --> 0.107056).  Saving model ...\n",
            "Epoch: 178 \tTraining Loss: 0.039610 \tValidation Loss: 0.106882\n",
            "Validation loss decreased (0.107056 --> 0.106882).  Saving model ...\n",
            "Epoch: 179 \tTraining Loss: 0.039575 \tValidation Loss: 0.106711\n",
            "Validation loss decreased (0.106882 --> 0.106711).  Saving model ...\n",
            "Epoch: 180 \tTraining Loss: 0.039541 \tValidation Loss: 0.106542\n",
            "Validation loss decreased (0.106711 --> 0.106542).  Saving model ...\n",
            "Epoch: 181 \tTraining Loss: 0.039507 \tValidation Loss: 0.106375\n",
            "Validation loss decreased (0.106542 --> 0.106375).  Saving model ...\n",
            "Epoch: 182 \tTraining Loss: 0.039473 \tValidation Loss: 0.106212\n",
            "Validation loss decreased (0.106375 --> 0.106212).  Saving model ...\n",
            "Epoch: 183 \tTraining Loss: 0.039439 \tValidation Loss: 0.106050\n",
            "Validation loss decreased (0.106212 --> 0.106050).  Saving model ...\n",
            "Epoch: 184 \tTraining Loss: 0.039406 \tValidation Loss: 0.105891\n",
            "Validation loss decreased (0.106050 --> 0.105891).  Saving model ...\n",
            "Epoch: 185 \tTraining Loss: 0.039373 \tValidation Loss: 0.105735\n",
            "Validation loss decreased (0.105891 --> 0.105735).  Saving model ...\n",
            "Epoch: 186 \tTraining Loss: 0.039340 \tValidation Loss: 0.105582\n",
            "Validation loss decreased (0.105735 --> 0.105582).  Saving model ...\n",
            "Epoch: 187 \tTraining Loss: 0.039307 \tValidation Loss: 0.105431\n",
            "Validation loss decreased (0.105582 --> 0.105431).  Saving model ...\n",
            "Epoch: 188 \tTraining Loss: 0.039275 \tValidation Loss: 0.105283\n",
            "Validation loss decreased (0.105431 --> 0.105283).  Saving model ...\n",
            "Epoch: 189 \tTraining Loss: 0.039242 \tValidation Loss: 0.105139\n",
            "Validation loss decreased (0.105283 --> 0.105139).  Saving model ...\n",
            "Epoch: 190 \tTraining Loss: 0.039210 \tValidation Loss: 0.104997\n",
            "Validation loss decreased (0.105139 --> 0.104997).  Saving model ...\n",
            "Epoch: 191 \tTraining Loss: 0.039178 \tValidation Loss: 0.104859\n",
            "Validation loss decreased (0.104997 --> 0.104859).  Saving model ...\n",
            "Epoch: 192 \tTraining Loss: 0.039147 \tValidation Loss: 0.104724\n",
            "Validation loss decreased (0.104859 --> 0.104724).  Saving model ...\n",
            "Epoch: 193 \tTraining Loss: 0.039115 \tValidation Loss: 0.104592\n",
            "Validation loss decreased (0.104724 --> 0.104592).  Saving model ...\n",
            "Epoch: 194 \tTraining Loss: 0.039084 \tValidation Loss: 0.104463\n",
            "Validation loss decreased (0.104592 --> 0.104463).  Saving model ...\n",
            "Epoch: 195 \tTraining Loss: 0.039053 \tValidation Loss: 0.104339\n",
            "Validation loss decreased (0.104463 --> 0.104339).  Saving model ...\n",
            "Epoch: 196 \tTraining Loss: 0.039022 \tValidation Loss: 0.104217\n",
            "Validation loss decreased (0.104339 --> 0.104217).  Saving model ...\n",
            "Epoch: 197 \tTraining Loss: 0.038992 \tValidation Loss: 0.104099\n",
            "Validation loss decreased (0.104217 --> 0.104099).  Saving model ...\n",
            "Epoch: 198 \tTraining Loss: 0.038961 \tValidation Loss: 0.103984\n",
            "Validation loss decreased (0.104099 --> 0.103984).  Saving model ...\n",
            "Epoch: 199 \tTraining Loss: 0.038931 \tValidation Loss: 0.103874\n",
            "Validation loss decreased (0.103984 --> 0.103874).  Saving model ...\n",
            "Epoch: 200 \tTraining Loss: 0.038901 \tValidation Loss: 0.103767\n",
            "Validation loss decreased (0.103874 --> 0.103767).  Saving model ...\n",
            "Epoch: 201 \tTraining Loss: 0.038871 \tValidation Loss: 0.103663\n",
            "Validation loss decreased (0.103767 --> 0.103663).  Saving model ...\n",
            "Epoch: 202 \tTraining Loss: 0.038841 \tValidation Loss: 0.103564\n",
            "Validation loss decreased (0.103663 --> 0.103564).  Saving model ...\n",
            "Epoch: 203 \tTraining Loss: 0.038811 \tValidation Loss: 0.103468\n",
            "Validation loss decreased (0.103564 --> 0.103468).  Saving model ...\n",
            "Epoch: 204 \tTraining Loss: 0.038782 \tValidation Loss: 0.103376\n",
            "Validation loss decreased (0.103468 --> 0.103376).  Saving model ...\n",
            "Epoch: 205 \tTraining Loss: 0.038752 \tValidation Loss: 0.103289\n",
            "Validation loss decreased (0.103376 --> 0.103289).  Saving model ...\n",
            "Epoch: 206 \tTraining Loss: 0.038723 \tValidation Loss: 0.103205\n",
            "Validation loss decreased (0.103289 --> 0.103205).  Saving model ...\n",
            "Epoch: 207 \tTraining Loss: 0.038694 \tValidation Loss: 0.103125\n",
            "Validation loss decreased (0.103205 --> 0.103125).  Saving model ...\n",
            "Epoch: 208 \tTraining Loss: 0.038665 \tValidation Loss: 0.103049\n",
            "Validation loss decreased (0.103125 --> 0.103049).  Saving model ...\n",
            "Epoch: 209 \tTraining Loss: 0.038636 \tValidation Loss: 0.102977\n",
            "Validation loss decreased (0.103049 --> 0.102977).  Saving model ...\n",
            "Epoch: 210 \tTraining Loss: 0.038608 \tValidation Loss: 0.102909\n",
            "Validation loss decreased (0.102977 --> 0.102909).  Saving model ...\n",
            "Epoch: 211 \tTraining Loss: 0.038579 \tValidation Loss: 0.102845\n",
            "Validation loss decreased (0.102909 --> 0.102845).  Saving model ...\n",
            "Epoch: 212 \tTraining Loss: 0.038551 \tValidation Loss: 0.102785\n",
            "Validation loss decreased (0.102845 --> 0.102785).  Saving model ...\n",
            "Epoch: 213 \tTraining Loss: 0.038522 \tValidation Loss: 0.102729\n",
            "Validation loss decreased (0.102785 --> 0.102729).  Saving model ...\n",
            "Epoch: 214 \tTraining Loss: 0.038494 \tValidation Loss: 0.102677\n",
            "Validation loss decreased (0.102729 --> 0.102677).  Saving model ...\n",
            "Epoch: 215 \tTraining Loss: 0.038466 \tValidation Loss: 0.102629\n",
            "Validation loss decreased (0.102677 --> 0.102629).  Saving model ...\n",
            "Epoch: 216 \tTraining Loss: 0.038438 \tValidation Loss: 0.102584\n",
            "Validation loss decreased (0.102629 --> 0.102584).  Saving model ...\n",
            "Epoch: 217 \tTraining Loss: 0.038411 \tValidation Loss: 0.102544\n",
            "Validation loss decreased (0.102584 --> 0.102544).  Saving model ...\n",
            "Epoch: 218 \tTraining Loss: 0.038383 \tValidation Loss: 0.102507\n",
            "Validation loss decreased (0.102544 --> 0.102507).  Saving model ...\n",
            "Epoch: 219 \tTraining Loss: 0.038355 \tValidation Loss: 0.102474\n",
            "Validation loss decreased (0.102507 --> 0.102474).  Saving model ...\n",
            "Epoch: 220 \tTraining Loss: 0.038328 \tValidation Loss: 0.102445\n",
            "Validation loss decreased (0.102474 --> 0.102445).  Saving model ...\n",
            "Epoch: 221 \tTraining Loss: 0.038301 \tValidation Loss: 0.102420\n",
            "Validation loss decreased (0.102445 --> 0.102420).  Saving model ...\n",
            "Epoch: 222 \tTraining Loss: 0.038273 \tValidation Loss: 0.102397\n",
            "Validation loss decreased (0.102420 --> 0.102397).  Saving model ...\n",
            "Epoch: 223 \tTraining Loss: 0.038246 \tValidation Loss: 0.102379\n",
            "Validation loss decreased (0.102397 --> 0.102379).  Saving model ...\n",
            "Epoch: 224 \tTraining Loss: 0.038220 \tValidation Loss: 0.102364\n",
            "Validation loss decreased (0.102379 --> 0.102364).  Saving model ...\n",
            "Epoch: 225 \tTraining Loss: 0.038193 \tValidation Loss: 0.102353\n",
            "Validation loss decreased (0.102364 --> 0.102353).  Saving model ...\n",
            "Epoch: 226 \tTraining Loss: 0.038166 \tValidation Loss: 0.102344\n",
            "Validation loss decreased (0.102353 --> 0.102344).  Saving model ...\n",
            "Epoch: 227 \tTraining Loss: 0.038140 \tValidation Loss: 0.102340\n",
            "Validation loss decreased (0.102344 --> 0.102340).  Saving model ...\n",
            "Epoch: 228 \tTraining Loss: 0.038113 \tValidation Loss: 0.102338\n",
            "Validation loss decreased (0.102340 --> 0.102338).  Saving model ...\n",
            "Epoch: 229 \tTraining Loss: 0.038087 \tValidation Loss: 0.102339\n",
            "Epoch: 230 \tTraining Loss: 0.038061 \tValidation Loss: 0.102344\n",
            "Epoch: 231 \tTraining Loss: 0.038035 \tValidation Loss: 0.102351\n",
            "Epoch: 232 \tTraining Loss: 0.038009 \tValidation Loss: 0.102360\n",
            "Epoch: 233 \tTraining Loss: 0.037983 \tValidation Loss: 0.102373\n",
            "Epoch: 234 \tTraining Loss: 0.037957 \tValidation Loss: 0.102388\n",
            "Epoch: 235 \tTraining Loss: 0.037932 \tValidation Loss: 0.102406\n",
            "Epoch: 236 \tTraining Loss: 0.037906 \tValidation Loss: 0.102425\n",
            "Epoch: 237 \tTraining Loss: 0.037881 \tValidation Loss: 0.102447\n",
            "Epoch: 238 \tTraining Loss: 0.037856 \tValidation Loss: 0.102471\n",
            "Epoch: 239 \tTraining Loss: 0.037831 \tValidation Loss: 0.102497\n",
            "Epoch: 240 \tTraining Loss: 0.037806 \tValidation Loss: 0.102524\n",
            "Epoch: 241 \tTraining Loss: 0.037781 \tValidation Loss: 0.102553\n",
            "Epoch: 242 \tTraining Loss: 0.037756 \tValidation Loss: 0.102584\n",
            "Epoch: 243 \tTraining Loss: 0.037732 \tValidation Loss: 0.102616\n",
            "Epoch: 244 \tTraining Loss: 0.037707 \tValidation Loss: 0.102649\n",
            "Epoch: 245 \tTraining Loss: 0.037683 \tValidation Loss: 0.102683\n",
            "Epoch: 246 \tTraining Loss: 0.037658 \tValidation Loss: 0.102719\n",
            "Epoch: 247 \tTraining Loss: 0.037634 \tValidation Loss: 0.102755\n",
            "Epoch: 248 \tTraining Loss: 0.037610 \tValidation Loss: 0.102793\n",
            "Epoch: 249 \tTraining Loss: 0.037586 \tValidation Loss: 0.102830\n",
            "Epoch: 250 \tTraining Loss: 0.037562 \tValidation Loss: 0.102868\n",
            "Epoch: 251 \tTraining Loss: 0.037539 \tValidation Loss: 0.102907\n",
            "Epoch: 252 \tTraining Loss: 0.037515 \tValidation Loss: 0.102945\n",
            "Epoch: 253 \tTraining Loss: 0.037491 \tValidation Loss: 0.102985\n",
            "Epoch: 254 \tTraining Loss: 0.037468 \tValidation Loss: 0.103024\n",
            "Epoch: 255 \tTraining Loss: 0.037444 \tValidation Loss: 0.103062\n",
            "Epoch: 256 \tTraining Loss: 0.037421 \tValidation Loss: 0.103101\n",
            "Epoch: 257 \tTraining Loss: 0.037398 \tValidation Loss: 0.103140\n",
            "Epoch: 258 \tTraining Loss: 0.037375 \tValidation Loss: 0.103178\n",
            "Epoch: 259 \tTraining Loss: 0.037352 \tValidation Loss: 0.103216\n",
            "Epoch: 260 \tTraining Loss: 0.037329 \tValidation Loss: 0.103254\n",
            "Epoch: 261 \tTraining Loss: 0.037306 \tValidation Loss: 0.103291\n",
            "Epoch: 262 \tTraining Loss: 0.037283 \tValidation Loss: 0.103327\n",
            "Epoch: 263 \tTraining Loss: 0.037260 \tValidation Loss: 0.103363\n",
            "Epoch: 264 \tTraining Loss: 0.037237 \tValidation Loss: 0.103398\n",
            "Epoch: 265 \tTraining Loss: 0.037215 \tValidation Loss: 0.103432\n",
            "Epoch: 266 \tTraining Loss: 0.037192 \tValidation Loss: 0.103466\n",
            "Epoch: 267 \tTraining Loss: 0.037169 \tValidation Loss: 0.103498\n",
            "Epoch: 268 \tTraining Loss: 0.037147 \tValidation Loss: 0.103530\n",
            "Epoch: 269 \tTraining Loss: 0.037124 \tValidation Loss: 0.103561\n",
            "Epoch: 270 \tTraining Loss: 0.037102 \tValidation Loss: 0.103591\n",
            "Epoch: 271 \tTraining Loss: 0.037080 \tValidation Loss: 0.103621\n",
            "Epoch: 272 \tTraining Loss: 0.037057 \tValidation Loss: 0.103650\n",
            "Epoch: 273 \tTraining Loss: 0.037035 \tValidation Loss: 0.103677\n",
            "Epoch: 274 \tTraining Loss: 0.037013 \tValidation Loss: 0.103703\n",
            "Epoch: 275 \tTraining Loss: 0.036991 \tValidation Loss: 0.103729\n",
            "Epoch: 276 \tTraining Loss: 0.036969 \tValidation Loss: 0.103755\n",
            "Epoch: 277 \tTraining Loss: 0.036947 \tValidation Loss: 0.103778\n",
            "Epoch: 278 \tTraining Loss: 0.036925 \tValidation Loss: 0.103801\n",
            "Epoch: 279 \tTraining Loss: 0.036903 \tValidation Loss: 0.103823\n",
            "Epoch: 280 \tTraining Loss: 0.036881 \tValidation Loss: 0.103844\n",
            "Epoch: 281 \tTraining Loss: 0.036859 \tValidation Loss: 0.103864\n",
            "Epoch: 282 \tTraining Loss: 0.036837 \tValidation Loss: 0.103884\n",
            "Epoch: 283 \tTraining Loss: 0.036815 \tValidation Loss: 0.103902\n",
            "Epoch: 284 \tTraining Loss: 0.036793 \tValidation Loss: 0.103920\n",
            "Epoch: 285 \tTraining Loss: 0.036772 \tValidation Loss: 0.103936\n",
            "Epoch: 286 \tTraining Loss: 0.036750 \tValidation Loss: 0.103952\n",
            "Epoch: 287 \tTraining Loss: 0.036728 \tValidation Loss: 0.103966\n",
            "Epoch: 288 \tTraining Loss: 0.036707 \tValidation Loss: 0.103980\n",
            "Epoch: 289 \tTraining Loss: 0.036685 \tValidation Loss: 0.103993\n",
            "Epoch: 290 \tTraining Loss: 0.036664 \tValidation Loss: 0.104005\n",
            "Epoch: 291 \tTraining Loss: 0.036642 \tValidation Loss: 0.104016\n",
            "Epoch: 292 \tTraining Loss: 0.036621 \tValidation Loss: 0.104026\n",
            "Epoch: 293 \tTraining Loss: 0.036600 \tValidation Loss: 0.104035\n",
            "Epoch: 294 \tTraining Loss: 0.036578 \tValidation Loss: 0.104043\n",
            "Epoch: 295 \tTraining Loss: 0.036557 \tValidation Loss: 0.104051\n",
            "Epoch: 296 \tTraining Loss: 0.036536 \tValidation Loss: 0.104057\n",
            "Epoch: 297 \tTraining Loss: 0.036515 \tValidation Loss: 0.104062\n",
            "Epoch: 298 \tTraining Loss: 0.036494 \tValidation Loss: 0.104067\n",
            "Epoch: 299 \tTraining Loss: 0.036473 \tValidation Loss: 0.104070\n",
            "Epoch: 300 \tTraining Loss: 0.036452 \tValidation Loss: 0.104073\n",
            "Epoch: 301 \tTraining Loss: 0.036431 \tValidation Loss: 0.104075\n",
            "Epoch: 302 \tTraining Loss: 0.036410 \tValidation Loss: 0.104076\n",
            "Epoch: 303 \tTraining Loss: 0.036389 \tValidation Loss: 0.104076\n",
            "Epoch: 304 \tTraining Loss: 0.036368 \tValidation Loss: 0.104075\n",
            "Epoch: 305 \tTraining Loss: 0.036348 \tValidation Loss: 0.104074\n",
            "Epoch: 306 \tTraining Loss: 0.036327 \tValidation Loss: 0.104072\n",
            "Epoch: 307 \tTraining Loss: 0.036306 \tValidation Loss: 0.104069\n",
            "Epoch: 308 \tTraining Loss: 0.036286 \tValidation Loss: 0.104065\n",
            "Epoch: 309 \tTraining Loss: 0.036265 \tValidation Loss: 0.104060\n",
            "Epoch: 310 \tTraining Loss: 0.036245 \tValidation Loss: 0.104054\n",
            "Epoch: 311 \tTraining Loss: 0.036224 \tValidation Loss: 0.104047\n",
            "Epoch: 312 \tTraining Loss: 0.036204 \tValidation Loss: 0.104040\n",
            "Epoch: 313 \tTraining Loss: 0.036184 \tValidation Loss: 0.104032\n",
            "Epoch: 314 \tTraining Loss: 0.036163 \tValidation Loss: 0.104023\n",
            "Epoch: 315 \tTraining Loss: 0.036143 \tValidation Loss: 0.104013\n",
            "Epoch: 316 \tTraining Loss: 0.036123 \tValidation Loss: 0.104003\n",
            "Epoch: 317 \tTraining Loss: 0.036103 \tValidation Loss: 0.103993\n",
            "Epoch: 318 \tTraining Loss: 0.036083 \tValidation Loss: 0.103981\n",
            "Epoch: 319 \tTraining Loss: 0.036063 \tValidation Loss: 0.103969\n",
            "Epoch: 320 \tTraining Loss: 0.036043 \tValidation Loss: 0.103955\n",
            "Epoch: 321 \tTraining Loss: 0.036023 \tValidation Loss: 0.103942\n",
            "Epoch: 322 \tTraining Loss: 0.036003 \tValidation Loss: 0.103927\n",
            "Epoch: 323 \tTraining Loss: 0.035983 \tValidation Loss: 0.103913\n",
            "Epoch: 324 \tTraining Loss: 0.035963 \tValidation Loss: 0.103897\n",
            "Epoch: 325 \tTraining Loss: 0.035943 \tValidation Loss: 0.103880\n",
            "Epoch: 326 \tTraining Loss: 0.035924 \tValidation Loss: 0.103863\n",
            "Epoch: 327 \tTraining Loss: 0.035904 \tValidation Loss: 0.103846\n",
            "Epoch: 328 \tTraining Loss: 0.035884 \tValidation Loss: 0.103827\n",
            "Epoch: 329 \tTraining Loss: 0.035865 \tValidation Loss: 0.103807\n",
            "Epoch: 330 \tTraining Loss: 0.035845 \tValidation Loss: 0.103787\n",
            "Epoch: 331 \tTraining Loss: 0.035825 \tValidation Loss: 0.103766\n",
            "Epoch: 332 \tTraining Loss: 0.035806 \tValidation Loss: 0.103745\n",
            "Epoch: 333 \tTraining Loss: 0.035786 \tValidation Loss: 0.103723\n",
            "Epoch: 334 \tTraining Loss: 0.035767 \tValidation Loss: 0.103699\n",
            "Epoch: 335 \tTraining Loss: 0.035747 \tValidation Loss: 0.103675\n",
            "Epoch: 336 \tTraining Loss: 0.035728 \tValidation Loss: 0.103649\n",
            "Epoch: 337 \tTraining Loss: 0.035709 \tValidation Loss: 0.103623\n",
            "Epoch: 338 \tTraining Loss: 0.035689 \tValidation Loss: 0.103596\n",
            "Epoch: 339 \tTraining Loss: 0.035670 \tValidation Loss: 0.103568\n",
            "Epoch: 340 \tTraining Loss: 0.035651 \tValidation Loss: 0.103538\n",
            "Epoch: 341 \tTraining Loss: 0.035632 \tValidation Loss: 0.103508\n",
            "Epoch: 342 \tTraining Loss: 0.035612 \tValidation Loss: 0.103477\n",
            "Epoch: 343 \tTraining Loss: 0.035593 \tValidation Loss: 0.103444\n",
            "Epoch: 344 \tTraining Loss: 0.035574 \tValidation Loss: 0.103410\n",
            "Epoch: 345 \tTraining Loss: 0.035555 \tValidation Loss: 0.103375\n",
            "Epoch: 346 \tTraining Loss: 0.035536 \tValidation Loss: 0.103339\n",
            "Epoch: 347 \tTraining Loss: 0.035518 \tValidation Loss: 0.103301\n",
            "Epoch: 348 \tTraining Loss: 0.035499 \tValidation Loss: 0.103262\n",
            "Epoch: 349 \tTraining Loss: 0.035480 \tValidation Loss: 0.103221\n",
            "Epoch: 350 \tTraining Loss: 0.035461 \tValidation Loss: 0.103179\n",
            "Epoch: 351 \tTraining Loss: 0.035443 \tValidation Loss: 0.103136\n",
            "Epoch: 352 \tTraining Loss: 0.035424 \tValidation Loss: 0.103091\n",
            "Epoch: 353 \tTraining Loss: 0.035405 \tValidation Loss: 0.103045\n",
            "Epoch: 354 \tTraining Loss: 0.035387 \tValidation Loss: 0.102998\n",
            "Epoch: 355 \tTraining Loss: 0.035369 \tValidation Loss: 0.102949\n",
            "Epoch: 356 \tTraining Loss: 0.035350 \tValidation Loss: 0.102899\n",
            "Epoch: 357 \tTraining Loss: 0.035332 \tValidation Loss: 0.102848\n",
            "Epoch: 358 \tTraining Loss: 0.035314 \tValidation Loss: 0.102795\n",
            "Epoch: 359 \tTraining Loss: 0.035295 \tValidation Loss: 0.102741\n",
            "Epoch: 360 \tTraining Loss: 0.035277 \tValidation Loss: 0.102686\n",
            "Epoch: 361 \tTraining Loss: 0.035259 \tValidation Loss: 0.102629\n",
            "Epoch: 362 \tTraining Loss: 0.035241 \tValidation Loss: 0.102572\n",
            "Epoch: 363 \tTraining Loss: 0.035223 \tValidation Loss: 0.102513\n",
            "Epoch: 364 \tTraining Loss: 0.035205 \tValidation Loss: 0.102453\n",
            "Epoch: 365 \tTraining Loss: 0.035187 \tValidation Loss: 0.102391\n",
            "Epoch: 366 \tTraining Loss: 0.035169 \tValidation Loss: 0.102330\n",
            "Validation loss decreased (0.102338 --> 0.102330).  Saving model ...\n",
            "Epoch: 367 \tTraining Loss: 0.035152 \tValidation Loss: 0.102266\n",
            "Validation loss decreased (0.102330 --> 0.102266).  Saving model ...\n",
            "Epoch: 368 \tTraining Loss: 0.035134 \tValidation Loss: 0.102202\n",
            "Validation loss decreased (0.102266 --> 0.102202).  Saving model ...\n",
            "Epoch: 369 \tTraining Loss: 0.035116 \tValidation Loss: 0.102137\n",
            "Validation loss decreased (0.102202 --> 0.102137).  Saving model ...\n",
            "Epoch: 370 \tTraining Loss: 0.035098 \tValidation Loss: 0.102071\n",
            "Validation loss decreased (0.102137 --> 0.102071).  Saving model ...\n",
            "Epoch: 371 \tTraining Loss: 0.035081 \tValidation Loss: 0.102003\n",
            "Validation loss decreased (0.102071 --> 0.102003).  Saving model ...\n",
            "Epoch: 372 \tTraining Loss: 0.035063 \tValidation Loss: 0.101935\n",
            "Validation loss decreased (0.102003 --> 0.101935).  Saving model ...\n",
            "Epoch: 373 \tTraining Loss: 0.035045 \tValidation Loss: 0.101866\n",
            "Validation loss decreased (0.101935 --> 0.101866).  Saving model ...\n",
            "Epoch: 374 \tTraining Loss: 0.035028 \tValidation Loss: 0.101797\n",
            "Validation loss decreased (0.101866 --> 0.101797).  Saving model ...\n",
            "Epoch: 375 \tTraining Loss: 0.035010 \tValidation Loss: 0.101727\n",
            "Validation loss decreased (0.101797 --> 0.101727).  Saving model ...\n",
            "Epoch: 376 \tTraining Loss: 0.034992 \tValidation Loss: 0.101655\n",
            "Validation loss decreased (0.101727 --> 0.101655).  Saving model ...\n",
            "Epoch: 377 \tTraining Loss: 0.034975 \tValidation Loss: 0.101583\n",
            "Validation loss decreased (0.101655 --> 0.101583).  Saving model ...\n",
            "Epoch: 378 \tTraining Loss: 0.034957 \tValidation Loss: 0.101510\n",
            "Validation loss decreased (0.101583 --> 0.101510).  Saving model ...\n",
            "Epoch: 379 \tTraining Loss: 0.034940 \tValidation Loss: 0.101437\n",
            "Validation loss decreased (0.101510 --> 0.101437).  Saving model ...\n",
            "Epoch: 380 \tTraining Loss: 0.034922 \tValidation Loss: 0.101364\n",
            "Validation loss decreased (0.101437 --> 0.101364).  Saving model ...\n",
            "Epoch: 381 \tTraining Loss: 0.034905 \tValidation Loss: 0.101288\n",
            "Validation loss decreased (0.101364 --> 0.101288).  Saving model ...\n",
            "Epoch: 382 \tTraining Loss: 0.034887 \tValidation Loss: 0.101213\n",
            "Validation loss decreased (0.101288 --> 0.101213).  Saving model ...\n",
            "Epoch: 383 \tTraining Loss: 0.034870 \tValidation Loss: 0.101137\n",
            "Validation loss decreased (0.101213 --> 0.101137).  Saving model ...\n",
            "Epoch: 384 \tTraining Loss: 0.034852 \tValidation Loss: 0.101060\n",
            "Validation loss decreased (0.101137 --> 0.101060).  Saving model ...\n",
            "Epoch: 385 \tTraining Loss: 0.034835 \tValidation Loss: 0.100983\n",
            "Validation loss decreased (0.101060 --> 0.100983).  Saving model ...\n",
            "Epoch: 386 \tTraining Loss: 0.034817 \tValidation Loss: 0.100905\n",
            "Validation loss decreased (0.100983 --> 0.100905).  Saving model ...\n",
            "Epoch: 387 \tTraining Loss: 0.034800 \tValidation Loss: 0.100827\n",
            "Validation loss decreased (0.100905 --> 0.100827).  Saving model ...\n",
            "Epoch: 388 \tTraining Loss: 0.034782 \tValidation Loss: 0.100748\n",
            "Validation loss decreased (0.100827 --> 0.100748).  Saving model ...\n",
            "Epoch: 389 \tTraining Loss: 0.034765 \tValidation Loss: 0.100669\n",
            "Validation loss decreased (0.100748 --> 0.100669).  Saving model ...\n",
            "Epoch: 390 \tTraining Loss: 0.034748 \tValidation Loss: 0.100589\n",
            "Validation loss decreased (0.100669 --> 0.100589).  Saving model ...\n",
            "Epoch: 391 \tTraining Loss: 0.034730 \tValidation Loss: 0.100508\n",
            "Validation loss decreased (0.100589 --> 0.100508).  Saving model ...\n",
            "Epoch: 392 \tTraining Loss: 0.034713 \tValidation Loss: 0.100427\n",
            "Validation loss decreased (0.100508 --> 0.100427).  Saving model ...\n",
            "Epoch: 393 \tTraining Loss: 0.034695 \tValidation Loss: 0.100346\n",
            "Validation loss decreased (0.100427 --> 0.100346).  Saving model ...\n",
            "Epoch: 394 \tTraining Loss: 0.034678 \tValidation Loss: 0.100264\n",
            "Validation loss decreased (0.100346 --> 0.100264).  Saving model ...\n",
            "Epoch: 395 \tTraining Loss: 0.034660 \tValidation Loss: 0.100182\n",
            "Validation loss decreased (0.100264 --> 0.100182).  Saving model ...\n",
            "Epoch: 396 \tTraining Loss: 0.034643 \tValidation Loss: 0.100099\n",
            "Validation loss decreased (0.100182 --> 0.100099).  Saving model ...\n",
            "Epoch: 397 \tTraining Loss: 0.034625 \tValidation Loss: 0.100015\n",
            "Validation loss decreased (0.100099 --> 0.100015).  Saving model ...\n",
            "Epoch: 398 \tTraining Loss: 0.034608 \tValidation Loss: 0.099931\n",
            "Validation loss decreased (0.100015 --> 0.099931).  Saving model ...\n",
            "Epoch: 399 \tTraining Loss: 0.034591 \tValidation Loss: 0.099847\n",
            "Validation loss decreased (0.099931 --> 0.099847).  Saving model ...\n",
            "Epoch: 400 \tTraining Loss: 0.034573 \tValidation Loss: 0.099762\n",
            "Validation loss decreased (0.099847 --> 0.099762).  Saving model ...\n",
            "Epoch: 401 \tTraining Loss: 0.034556 \tValidation Loss: 0.099677\n",
            "Validation loss decreased (0.099762 --> 0.099677).  Saving model ...\n",
            "Epoch: 402 \tTraining Loss: 0.034538 \tValidation Loss: 0.099591\n",
            "Validation loss decreased (0.099677 --> 0.099591).  Saving model ...\n",
            "Epoch: 403 \tTraining Loss: 0.034521 \tValidation Loss: 0.099506\n",
            "Validation loss decreased (0.099591 --> 0.099506).  Saving model ...\n",
            "Epoch: 404 \tTraining Loss: 0.034504 \tValidation Loss: 0.099419\n",
            "Validation loss decreased (0.099506 --> 0.099419).  Saving model ...\n",
            "Epoch: 405 \tTraining Loss: 0.034486 \tValidation Loss: 0.099332\n",
            "Validation loss decreased (0.099419 --> 0.099332).  Saving model ...\n",
            "Epoch: 406 \tTraining Loss: 0.034469 \tValidation Loss: 0.099245\n",
            "Validation loss decreased (0.099332 --> 0.099245).  Saving model ...\n",
            "Epoch: 407 \tTraining Loss: 0.034451 \tValidation Loss: 0.099157\n",
            "Validation loss decreased (0.099245 --> 0.099157).  Saving model ...\n",
            "Epoch: 408 \tTraining Loss: 0.034434 \tValidation Loss: 0.099070\n",
            "Validation loss decreased (0.099157 --> 0.099070).  Saving model ...\n",
            "Epoch: 409 \tTraining Loss: 0.034417 \tValidation Loss: 0.098981\n",
            "Validation loss decreased (0.099070 --> 0.098981).  Saving model ...\n",
            "Epoch: 410 \tTraining Loss: 0.034399 \tValidation Loss: 0.098893\n",
            "Validation loss decreased (0.098981 --> 0.098893).  Saving model ...\n",
            "Epoch: 411 \tTraining Loss: 0.034382 \tValidation Loss: 0.098804\n",
            "Validation loss decreased (0.098893 --> 0.098804).  Saving model ...\n",
            "Epoch: 412 \tTraining Loss: 0.034365 \tValidation Loss: 0.098715\n",
            "Validation loss decreased (0.098804 --> 0.098715).  Saving model ...\n",
            "Epoch: 413 \tTraining Loss: 0.034347 \tValidation Loss: 0.098626\n",
            "Validation loss decreased (0.098715 --> 0.098626).  Saving model ...\n",
            "Epoch: 414 \tTraining Loss: 0.034330 \tValidation Loss: 0.098536\n",
            "Validation loss decreased (0.098626 --> 0.098536).  Saving model ...\n",
            "Epoch: 415 \tTraining Loss: 0.034313 \tValidation Loss: 0.098446\n",
            "Validation loss decreased (0.098536 --> 0.098446).  Saving model ...\n",
            "Epoch: 416 \tTraining Loss: 0.034295 \tValidation Loss: 0.098355\n",
            "Validation loss decreased (0.098446 --> 0.098355).  Saving model ...\n",
            "Epoch: 417 \tTraining Loss: 0.034278 \tValidation Loss: 0.098265\n",
            "Validation loss decreased (0.098355 --> 0.098265).  Saving model ...\n",
            "Epoch: 418 \tTraining Loss: 0.034261 \tValidation Loss: 0.098174\n",
            "Validation loss decreased (0.098265 --> 0.098174).  Saving model ...\n",
            "Epoch: 419 \tTraining Loss: 0.034244 \tValidation Loss: 0.098083\n",
            "Validation loss decreased (0.098174 --> 0.098083).  Saving model ...\n",
            "Epoch: 420 \tTraining Loss: 0.034226 \tValidation Loss: 0.097992\n",
            "Validation loss decreased (0.098083 --> 0.097992).  Saving model ...\n",
            "Epoch: 421 \tTraining Loss: 0.034209 \tValidation Loss: 0.097900\n",
            "Validation loss decreased (0.097992 --> 0.097900).  Saving model ...\n",
            "Epoch: 422 \tTraining Loss: 0.034192 \tValidation Loss: 0.097809\n",
            "Validation loss decreased (0.097900 --> 0.097809).  Saving model ...\n",
            "Epoch: 423 \tTraining Loss: 0.034175 \tValidation Loss: 0.097717\n",
            "Validation loss decreased (0.097809 --> 0.097717).  Saving model ...\n",
            "Epoch: 424 \tTraining Loss: 0.034158 \tValidation Loss: 0.097625\n",
            "Validation loss decreased (0.097717 --> 0.097625).  Saving model ...\n",
            "Epoch: 425 \tTraining Loss: 0.034141 \tValidation Loss: 0.097533\n",
            "Validation loss decreased (0.097625 --> 0.097533).  Saving model ...\n",
            "Epoch: 426 \tTraining Loss: 0.034124 \tValidation Loss: 0.097440\n",
            "Validation loss decreased (0.097533 --> 0.097440).  Saving model ...\n",
            "Epoch: 427 \tTraining Loss: 0.034107 \tValidation Loss: 0.097347\n",
            "Validation loss decreased (0.097440 --> 0.097347).  Saving model ...\n",
            "Epoch: 428 \tTraining Loss: 0.034089 \tValidation Loss: 0.097254\n",
            "Validation loss decreased (0.097347 --> 0.097254).  Saving model ...\n",
            "Epoch: 429 \tTraining Loss: 0.034073 \tValidation Loss: 0.097161\n",
            "Validation loss decreased (0.097254 --> 0.097161).  Saving model ...\n",
            "Epoch: 430 \tTraining Loss: 0.034056 \tValidation Loss: 0.097068\n",
            "Validation loss decreased (0.097161 --> 0.097068).  Saving model ...\n",
            "Epoch: 431 \tTraining Loss: 0.034039 \tValidation Loss: 0.096975\n",
            "Validation loss decreased (0.097068 --> 0.096975).  Saving model ...\n",
            "Epoch: 432 \tTraining Loss: 0.034022 \tValidation Loss: 0.096881\n",
            "Validation loss decreased (0.096975 --> 0.096881).  Saving model ...\n",
            "Epoch: 433 \tTraining Loss: 0.034005 \tValidation Loss: 0.096788\n",
            "Validation loss decreased (0.096881 --> 0.096788).  Saving model ...\n",
            "Epoch: 434 \tTraining Loss: 0.033988 \tValidation Loss: 0.096694\n",
            "Validation loss decreased (0.096788 --> 0.096694).  Saving model ...\n",
            "Epoch: 435 \tTraining Loss: 0.033971 \tValidation Loss: 0.096600\n",
            "Validation loss decreased (0.096694 --> 0.096600).  Saving model ...\n",
            "Epoch: 436 \tTraining Loss: 0.033955 \tValidation Loss: 0.096506\n",
            "Validation loss decreased (0.096600 --> 0.096506).  Saving model ...\n",
            "Epoch: 437 \tTraining Loss: 0.033938 \tValidation Loss: 0.096411\n",
            "Validation loss decreased (0.096506 --> 0.096411).  Saving model ...\n",
            "Epoch: 438 \tTraining Loss: 0.033921 \tValidation Loss: 0.096317\n",
            "Validation loss decreased (0.096411 --> 0.096317).  Saving model ...\n",
            "Epoch: 439 \tTraining Loss: 0.033905 \tValidation Loss: 0.096222\n",
            "Validation loss decreased (0.096317 --> 0.096222).  Saving model ...\n",
            "Epoch: 440 \tTraining Loss: 0.033888 \tValidation Loss: 0.096128\n",
            "Validation loss decreased (0.096222 --> 0.096128).  Saving model ...\n",
            "Epoch: 441 \tTraining Loss: 0.033872 \tValidation Loss: 0.096032\n",
            "Validation loss decreased (0.096128 --> 0.096032).  Saving model ...\n",
            "Epoch: 442 \tTraining Loss: 0.033855 \tValidation Loss: 0.095937\n",
            "Validation loss decreased (0.096032 --> 0.095937).  Saving model ...\n",
            "Epoch: 443 \tTraining Loss: 0.033839 \tValidation Loss: 0.095842\n",
            "Validation loss decreased (0.095937 --> 0.095842).  Saving model ...\n",
            "Epoch: 444 \tTraining Loss: 0.033823 \tValidation Loss: 0.095746\n",
            "Validation loss decreased (0.095842 --> 0.095746).  Saving model ...\n",
            "Epoch: 445 \tTraining Loss: 0.033806 \tValidation Loss: 0.095651\n",
            "Validation loss decreased (0.095746 --> 0.095651).  Saving model ...\n",
            "Epoch: 446 \tTraining Loss: 0.033790 \tValidation Loss: 0.095555\n",
            "Validation loss decreased (0.095651 --> 0.095555).  Saving model ...\n",
            "Epoch: 447 \tTraining Loss: 0.033774 \tValidation Loss: 0.095459\n",
            "Validation loss decreased (0.095555 --> 0.095459).  Saving model ...\n",
            "Epoch: 448 \tTraining Loss: 0.033758 \tValidation Loss: 0.095363\n",
            "Validation loss decreased (0.095459 --> 0.095363).  Saving model ...\n",
            "Epoch: 449 \tTraining Loss: 0.033742 \tValidation Loss: 0.095267\n",
            "Validation loss decreased (0.095363 --> 0.095267).  Saving model ...\n",
            "Epoch: 450 \tTraining Loss: 0.033725 \tValidation Loss: 0.095170\n",
            "Validation loss decreased (0.095267 --> 0.095170).  Saving model ...\n",
            "Epoch: 451 \tTraining Loss: 0.033709 \tValidation Loss: 0.095074\n",
            "Validation loss decreased (0.095170 --> 0.095074).  Saving model ...\n",
            "Epoch: 452 \tTraining Loss: 0.033694 \tValidation Loss: 0.094977\n",
            "Validation loss decreased (0.095074 --> 0.094977).  Saving model ...\n",
            "Epoch: 453 \tTraining Loss: 0.033678 \tValidation Loss: 0.094880\n",
            "Validation loss decreased (0.094977 --> 0.094880).  Saving model ...\n",
            "Epoch: 454 \tTraining Loss: 0.033662 \tValidation Loss: 0.094783\n",
            "Validation loss decreased (0.094880 --> 0.094783).  Saving model ...\n",
            "Epoch: 455 \tTraining Loss: 0.033646 \tValidation Loss: 0.094686\n",
            "Validation loss decreased (0.094783 --> 0.094686).  Saving model ...\n",
            "Epoch: 456 \tTraining Loss: 0.033630 \tValidation Loss: 0.094589\n",
            "Validation loss decreased (0.094686 --> 0.094589).  Saving model ...\n",
            "Epoch: 457 \tTraining Loss: 0.033615 \tValidation Loss: 0.094491\n",
            "Validation loss decreased (0.094589 --> 0.094491).  Saving model ...\n",
            "Epoch: 458 \tTraining Loss: 0.033599 \tValidation Loss: 0.094394\n",
            "Validation loss decreased (0.094491 --> 0.094394).  Saving model ...\n",
            "Epoch: 459 \tTraining Loss: 0.033583 \tValidation Loss: 0.094296\n",
            "Validation loss decreased (0.094394 --> 0.094296).  Saving model ...\n",
            "Epoch: 460 \tTraining Loss: 0.033568 \tValidation Loss: 0.094198\n",
            "Validation loss decreased (0.094296 --> 0.094198).  Saving model ...\n",
            "Epoch: 461 \tTraining Loss: 0.033552 \tValidation Loss: 0.094100\n",
            "Validation loss decreased (0.094198 --> 0.094100).  Saving model ...\n",
            "Epoch: 462 \tTraining Loss: 0.033537 \tValidation Loss: 0.094002\n",
            "Validation loss decreased (0.094100 --> 0.094002).  Saving model ...\n",
            "Epoch: 463 \tTraining Loss: 0.033522 \tValidation Loss: 0.093903\n",
            "Validation loss decreased (0.094002 --> 0.093903).  Saving model ...\n",
            "Epoch: 464 \tTraining Loss: 0.033506 \tValidation Loss: 0.093805\n",
            "Validation loss decreased (0.093903 --> 0.093805).  Saving model ...\n",
            "Epoch: 465 \tTraining Loss: 0.033491 \tValidation Loss: 0.093706\n",
            "Validation loss decreased (0.093805 --> 0.093706).  Saving model ...\n",
            "Epoch: 466 \tTraining Loss: 0.033476 \tValidation Loss: 0.093607\n",
            "Validation loss decreased (0.093706 --> 0.093607).  Saving model ...\n",
            "Epoch: 467 \tTraining Loss: 0.033461 \tValidation Loss: 0.093509\n",
            "Validation loss decreased (0.093607 --> 0.093509).  Saving model ...\n",
            "Epoch: 468 \tTraining Loss: 0.033446 \tValidation Loss: 0.093410\n",
            "Validation loss decreased (0.093509 --> 0.093410).  Saving model ...\n",
            "Epoch: 469 \tTraining Loss: 0.033431 \tValidation Loss: 0.093311\n",
            "Validation loss decreased (0.093410 --> 0.093311).  Saving model ...\n",
            "Epoch: 470 \tTraining Loss: 0.033416 \tValidation Loss: 0.093212\n",
            "Validation loss decreased (0.093311 --> 0.093212).  Saving model ...\n",
            "Epoch: 471 \tTraining Loss: 0.033401 \tValidation Loss: 0.093113\n",
            "Validation loss decreased (0.093212 --> 0.093113).  Saving model ...\n",
            "Epoch: 472 \tTraining Loss: 0.033386 \tValidation Loss: 0.093014\n",
            "Validation loss decreased (0.093113 --> 0.093014).  Saving model ...\n",
            "Epoch: 473 \tTraining Loss: 0.033371 \tValidation Loss: 0.092915\n",
            "Validation loss decreased (0.093014 --> 0.092915).  Saving model ...\n",
            "Epoch: 474 \tTraining Loss: 0.033357 \tValidation Loss: 0.092816\n",
            "Validation loss decreased (0.092915 --> 0.092816).  Saving model ...\n",
            "Epoch: 475 \tTraining Loss: 0.033342 \tValidation Loss: 0.092717\n",
            "Validation loss decreased (0.092816 --> 0.092717).  Saving model ...\n",
            "Epoch: 476 \tTraining Loss: 0.033327 \tValidation Loss: 0.092617\n",
            "Validation loss decreased (0.092717 --> 0.092617).  Saving model ...\n",
            "Epoch: 477 \tTraining Loss: 0.033313 \tValidation Loss: 0.092518\n",
            "Validation loss decreased (0.092617 --> 0.092518).  Saving model ...\n",
            "Epoch: 478 \tTraining Loss: 0.033298 \tValidation Loss: 0.092419\n",
            "Validation loss decreased (0.092518 --> 0.092419).  Saving model ...\n",
            "Epoch: 479 \tTraining Loss: 0.033284 \tValidation Loss: 0.092319\n",
            "Validation loss decreased (0.092419 --> 0.092319).  Saving model ...\n",
            "Epoch: 480 \tTraining Loss: 0.033269 \tValidation Loss: 0.092220\n",
            "Validation loss decreased (0.092319 --> 0.092220).  Saving model ...\n",
            "Epoch: 481 \tTraining Loss: 0.033255 \tValidation Loss: 0.092121\n",
            "Validation loss decreased (0.092220 --> 0.092121).  Saving model ...\n",
            "Epoch: 482 \tTraining Loss: 0.033241 \tValidation Loss: 0.092022\n",
            "Validation loss decreased (0.092121 --> 0.092022).  Saving model ...\n",
            "Epoch: 483 \tTraining Loss: 0.033226 \tValidation Loss: 0.091923\n",
            "Validation loss decreased (0.092022 --> 0.091923).  Saving model ...\n",
            "Epoch: 484 \tTraining Loss: 0.033212 \tValidation Loss: 0.091824\n",
            "Validation loss decreased (0.091923 --> 0.091824).  Saving model ...\n",
            "Epoch: 485 \tTraining Loss: 0.033198 \tValidation Loss: 0.091725\n",
            "Validation loss decreased (0.091824 --> 0.091725).  Saving model ...\n",
            "Epoch: 486 \tTraining Loss: 0.033184 \tValidation Loss: 0.091626\n",
            "Validation loss decreased (0.091725 --> 0.091626).  Saving model ...\n",
            "Epoch: 487 \tTraining Loss: 0.033170 \tValidation Loss: 0.091527\n",
            "Validation loss decreased (0.091626 --> 0.091527).  Saving model ...\n",
            "Epoch: 488 \tTraining Loss: 0.033156 \tValidation Loss: 0.091428\n",
            "Validation loss decreased (0.091527 --> 0.091428).  Saving model ...\n",
            "Epoch: 489 \tTraining Loss: 0.033142 \tValidation Loss: 0.091330\n",
            "Validation loss decreased (0.091428 --> 0.091330).  Saving model ...\n",
            "Epoch: 490 \tTraining Loss: 0.033128 \tValidation Loss: 0.091231\n",
            "Validation loss decreased (0.091330 --> 0.091231).  Saving model ...\n",
            "Epoch: 491 \tTraining Loss: 0.033114 \tValidation Loss: 0.091132\n",
            "Validation loss decreased (0.091231 --> 0.091132).  Saving model ...\n",
            "Epoch: 492 \tTraining Loss: 0.033100 \tValidation Loss: 0.091034\n",
            "Validation loss decreased (0.091132 --> 0.091034).  Saving model ...\n",
            "Epoch: 493 \tTraining Loss: 0.033087 \tValidation Loss: 0.090935\n",
            "Validation loss decreased (0.091034 --> 0.090935).  Saving model ...\n",
            "Epoch: 494 \tTraining Loss: 0.033073 \tValidation Loss: 0.090838\n",
            "Validation loss decreased (0.090935 --> 0.090838).  Saving model ...\n",
            "Epoch: 495 \tTraining Loss: 0.033059 \tValidation Loss: 0.090740\n",
            "Validation loss decreased (0.090838 --> 0.090740).  Saving model ...\n",
            "Epoch: 496 \tTraining Loss: 0.033046 \tValidation Loss: 0.090642\n",
            "Validation loss decreased (0.090740 --> 0.090642).  Saving model ...\n",
            "Epoch: 497 \tTraining Loss: 0.033032 \tValidation Loss: 0.090545\n",
            "Validation loss decreased (0.090642 --> 0.090545).  Saving model ...\n",
            "Epoch: 498 \tTraining Loss: 0.033019 \tValidation Loss: 0.090448\n",
            "Validation loss decreased (0.090545 --> 0.090448).  Saving model ...\n",
            "Epoch: 499 \tTraining Loss: 0.033005 \tValidation Loss: 0.090351\n",
            "Validation loss decreased (0.090448 --> 0.090351).  Saving model ...\n",
            "Epoch: 500 \tTraining Loss: 0.032992 \tValidation Loss: 0.090254\n",
            "Validation loss decreased (0.090351 --> 0.090254).  Saving model ...\n",
            "Epoch: 501 \tTraining Loss: 0.032978 \tValidation Loss: 0.090157\n",
            "Validation loss decreased (0.090254 --> 0.090157).  Saving model ...\n",
            "Epoch: 502 \tTraining Loss: 0.032965 \tValidation Loss: 0.090061\n",
            "Validation loss decreased (0.090157 --> 0.090061).  Saving model ...\n",
            "Epoch: 503 \tTraining Loss: 0.032952 \tValidation Loss: 0.089965\n",
            "Validation loss decreased (0.090061 --> 0.089965).  Saving model ...\n",
            "Epoch: 504 \tTraining Loss: 0.032938 \tValidation Loss: 0.089869\n",
            "Validation loss decreased (0.089965 --> 0.089869).  Saving model ...\n",
            "Epoch: 505 \tTraining Loss: 0.032925 \tValidation Loss: 0.089773\n",
            "Validation loss decreased (0.089869 --> 0.089773).  Saving model ...\n",
            "Epoch: 506 \tTraining Loss: 0.032912 \tValidation Loss: 0.089678\n",
            "Validation loss decreased (0.089773 --> 0.089678).  Saving model ...\n",
            "Epoch: 507 \tTraining Loss: 0.032899 \tValidation Loss: 0.089583\n",
            "Validation loss decreased (0.089678 --> 0.089583).  Saving model ...\n",
            "Epoch: 508 \tTraining Loss: 0.032886 \tValidation Loss: 0.089489\n",
            "Validation loss decreased (0.089583 --> 0.089489).  Saving model ...\n",
            "Epoch: 509 \tTraining Loss: 0.032873 \tValidation Loss: 0.089394\n",
            "Validation loss decreased (0.089489 --> 0.089394).  Saving model ...\n",
            "Epoch: 510 \tTraining Loss: 0.032860 \tValidation Loss: 0.089301\n",
            "Validation loss decreased (0.089394 --> 0.089301).  Saving model ...\n",
            "Epoch: 511 \tTraining Loss: 0.032847 \tValidation Loss: 0.089207\n",
            "Validation loss decreased (0.089301 --> 0.089207).  Saving model ...\n",
            "Epoch: 512 \tTraining Loss: 0.032834 \tValidation Loss: 0.089114\n",
            "Validation loss decreased (0.089207 --> 0.089114).  Saving model ...\n",
            "Epoch: 513 \tTraining Loss: 0.032821 \tValidation Loss: 0.089021\n",
            "Validation loss decreased (0.089114 --> 0.089021).  Saving model ...\n",
            "Epoch: 514 \tTraining Loss: 0.032808 \tValidation Loss: 0.088929\n",
            "Validation loss decreased (0.089021 --> 0.088929).  Saving model ...\n",
            "Epoch: 515 \tTraining Loss: 0.032795 \tValidation Loss: 0.088837\n",
            "Validation loss decreased (0.088929 --> 0.088837).  Saving model ...\n",
            "Epoch: 516 \tTraining Loss: 0.032782 \tValidation Loss: 0.088746\n",
            "Validation loss decreased (0.088837 --> 0.088746).  Saving model ...\n",
            "Epoch: 517 \tTraining Loss: 0.032770 \tValidation Loss: 0.088654\n",
            "Validation loss decreased (0.088746 --> 0.088654).  Saving model ...\n",
            "Epoch: 518 \tTraining Loss: 0.032757 \tValidation Loss: 0.088564\n",
            "Validation loss decreased (0.088654 --> 0.088564).  Saving model ...\n",
            "Epoch: 519 \tTraining Loss: 0.032744 \tValidation Loss: 0.088473\n",
            "Validation loss decreased (0.088564 --> 0.088473).  Saving model ...\n",
            "Epoch: 520 \tTraining Loss: 0.032732 \tValidation Loss: 0.088384\n",
            "Validation loss decreased (0.088473 --> 0.088384).  Saving model ...\n",
            "Epoch: 521 \tTraining Loss: 0.032719 \tValidation Loss: 0.088295\n",
            "Validation loss decreased (0.088384 --> 0.088295).  Saving model ...\n",
            "Epoch: 522 \tTraining Loss: 0.032707 \tValidation Loss: 0.088206\n",
            "Validation loss decreased (0.088295 --> 0.088206).  Saving model ...\n",
            "Epoch: 523 \tTraining Loss: 0.032694 \tValidation Loss: 0.088118\n",
            "Validation loss decreased (0.088206 --> 0.088118).  Saving model ...\n",
            "Epoch: 524 \tTraining Loss: 0.032682 \tValidation Loss: 0.088030\n",
            "Validation loss decreased (0.088118 --> 0.088030).  Saving model ...\n",
            "Epoch: 525 \tTraining Loss: 0.032669 \tValidation Loss: 0.087942\n",
            "Validation loss decreased (0.088030 --> 0.087942).  Saving model ...\n",
            "Epoch: 526 \tTraining Loss: 0.032657 \tValidation Loss: 0.087856\n",
            "Validation loss decreased (0.087942 --> 0.087856).  Saving model ...\n",
            "Epoch: 527 \tTraining Loss: 0.032645 \tValidation Loss: 0.087769\n",
            "Validation loss decreased (0.087856 --> 0.087769).  Saving model ...\n",
            "Epoch: 528 \tTraining Loss: 0.032632 \tValidation Loss: 0.087684\n",
            "Validation loss decreased (0.087769 --> 0.087684).  Saving model ...\n",
            "Epoch: 529 \tTraining Loss: 0.032620 \tValidation Loss: 0.087599\n",
            "Validation loss decreased (0.087684 --> 0.087599).  Saving model ...\n",
            "Epoch: 530 \tTraining Loss: 0.032608 \tValidation Loss: 0.087514\n",
            "Validation loss decreased (0.087599 --> 0.087514).  Saving model ...\n",
            "Epoch: 531 \tTraining Loss: 0.032596 \tValidation Loss: 0.087430\n",
            "Validation loss decreased (0.087514 --> 0.087430).  Saving model ...\n",
            "Epoch: 532 \tTraining Loss: 0.032584 \tValidation Loss: 0.087347\n",
            "Validation loss decreased (0.087430 --> 0.087347).  Saving model ...\n",
            "Epoch: 533 \tTraining Loss: 0.032572 \tValidation Loss: 0.087264\n",
            "Validation loss decreased (0.087347 --> 0.087264).  Saving model ...\n",
            "Epoch: 534 \tTraining Loss: 0.032560 \tValidation Loss: 0.087183\n",
            "Validation loss decreased (0.087264 --> 0.087183).  Saving model ...\n",
            "Epoch: 535 \tTraining Loss: 0.032548 \tValidation Loss: 0.087101\n",
            "Validation loss decreased (0.087183 --> 0.087101).  Saving model ...\n",
            "Epoch: 536 \tTraining Loss: 0.032536 \tValidation Loss: 0.087020\n",
            "Validation loss decreased (0.087101 --> 0.087020).  Saving model ...\n",
            "Epoch: 537 \tTraining Loss: 0.032524 \tValidation Loss: 0.086940\n",
            "Validation loss decreased (0.087020 --> 0.086940).  Saving model ...\n",
            "Epoch: 538 \tTraining Loss: 0.032512 \tValidation Loss: 0.086860\n",
            "Validation loss decreased (0.086940 --> 0.086860).  Saving model ...\n",
            "Epoch: 539 \tTraining Loss: 0.032500 \tValidation Loss: 0.086781\n",
            "Validation loss decreased (0.086860 --> 0.086781).  Saving model ...\n",
            "Epoch: 540 \tTraining Loss: 0.032488 \tValidation Loss: 0.086703\n",
            "Validation loss decreased (0.086781 --> 0.086703).  Saving model ...\n",
            "Epoch: 541 \tTraining Loss: 0.032477 \tValidation Loss: 0.086625\n",
            "Validation loss decreased (0.086703 --> 0.086625).  Saving model ...\n",
            "Epoch: 542 \tTraining Loss: 0.032465 \tValidation Loss: 0.086548\n",
            "Validation loss decreased (0.086625 --> 0.086548).  Saving model ...\n",
            "Epoch: 543 \tTraining Loss: 0.032453 \tValidation Loss: 0.086472\n",
            "Validation loss decreased (0.086548 --> 0.086472).  Saving model ...\n",
            "Epoch: 544 \tTraining Loss: 0.032442 \tValidation Loss: 0.086396\n",
            "Validation loss decreased (0.086472 --> 0.086396).  Saving model ...\n",
            "Epoch: 545 \tTraining Loss: 0.032430 \tValidation Loss: 0.086321\n",
            "Validation loss decreased (0.086396 --> 0.086321).  Saving model ...\n",
            "Epoch: 546 \tTraining Loss: 0.032419 \tValidation Loss: 0.086247\n",
            "Validation loss decreased (0.086321 --> 0.086247).  Saving model ...\n",
            "Epoch: 547 \tTraining Loss: 0.032407 \tValidation Loss: 0.086173\n",
            "Validation loss decreased (0.086247 --> 0.086173).  Saving model ...\n",
            "Epoch: 548 \tTraining Loss: 0.032396 \tValidation Loss: 0.086101\n",
            "Validation loss decreased (0.086173 --> 0.086101).  Saving model ...\n",
            "Epoch: 549 \tTraining Loss: 0.032385 \tValidation Loss: 0.086029\n",
            "Validation loss decreased (0.086101 --> 0.086029).  Saving model ...\n",
            "Epoch: 550 \tTraining Loss: 0.032373 \tValidation Loss: 0.085957\n",
            "Validation loss decreased (0.086029 --> 0.085957).  Saving model ...\n",
            "Epoch: 551 \tTraining Loss: 0.032362 \tValidation Loss: 0.085887\n",
            "Validation loss decreased (0.085957 --> 0.085887).  Saving model ...\n",
            "Epoch: 552 \tTraining Loss: 0.032351 \tValidation Loss: 0.085817\n",
            "Validation loss decreased (0.085887 --> 0.085817).  Saving model ...\n",
            "Epoch: 553 \tTraining Loss: 0.032339 \tValidation Loss: 0.085748\n",
            "Validation loss decreased (0.085817 --> 0.085748).  Saving model ...\n",
            "Epoch: 554 \tTraining Loss: 0.032328 \tValidation Loss: 0.085679\n",
            "Validation loss decreased (0.085748 --> 0.085679).  Saving model ...\n",
            "Epoch: 555 \tTraining Loss: 0.032317 \tValidation Loss: 0.085611\n",
            "Validation loss decreased (0.085679 --> 0.085611).  Saving model ...\n",
            "Epoch: 556 \tTraining Loss: 0.032306 \tValidation Loss: 0.085544\n",
            "Validation loss decreased (0.085611 --> 0.085544).  Saving model ...\n",
            "Epoch: 557 \tTraining Loss: 0.032295 \tValidation Loss: 0.085478\n",
            "Validation loss decreased (0.085544 --> 0.085478).  Saving model ...\n",
            "Epoch: 558 \tTraining Loss: 0.032284 \tValidation Loss: 0.085413\n",
            "Validation loss decreased (0.085478 --> 0.085413).  Saving model ...\n",
            "Epoch: 559 \tTraining Loss: 0.032273 \tValidation Loss: 0.085348\n",
            "Validation loss decreased (0.085413 --> 0.085348).  Saving model ...\n",
            "Epoch: 560 \tTraining Loss: 0.032262 \tValidation Loss: 0.085284\n",
            "Validation loss decreased (0.085348 --> 0.085284).  Saving model ...\n",
            "Epoch: 561 \tTraining Loss: 0.032251 \tValidation Loss: 0.085221\n",
            "Validation loss decreased (0.085284 --> 0.085221).  Saving model ...\n",
            "Epoch: 562 \tTraining Loss: 0.032241 \tValidation Loss: 0.085158\n",
            "Validation loss decreased (0.085221 --> 0.085158).  Saving model ...\n",
            "Epoch: 563 \tTraining Loss: 0.032230 \tValidation Loss: 0.085096\n",
            "Validation loss decreased (0.085158 --> 0.085096).  Saving model ...\n",
            "Epoch: 564 \tTraining Loss: 0.032219 \tValidation Loss: 0.085035\n",
            "Validation loss decreased (0.085096 --> 0.085035).  Saving model ...\n",
            "Epoch: 565 \tTraining Loss: 0.032208 \tValidation Loss: 0.084975\n",
            "Validation loss decreased (0.085035 --> 0.084975).  Saving model ...\n",
            "Epoch: 566 \tTraining Loss: 0.032198 \tValidation Loss: 0.084916\n",
            "Validation loss decreased (0.084975 --> 0.084916).  Saving model ...\n",
            "Epoch: 567 \tTraining Loss: 0.032187 \tValidation Loss: 0.084857\n",
            "Validation loss decreased (0.084916 --> 0.084857).  Saving model ...\n",
            "Epoch: 568 \tTraining Loss: 0.032177 \tValidation Loss: 0.084799\n",
            "Validation loss decreased (0.084857 --> 0.084799).  Saving model ...\n",
            "Epoch: 569 \tTraining Loss: 0.032166 \tValidation Loss: 0.084742\n",
            "Validation loss decreased (0.084799 --> 0.084742).  Saving model ...\n",
            "Epoch: 570 \tTraining Loss: 0.032156 \tValidation Loss: 0.084685\n",
            "Validation loss decreased (0.084742 --> 0.084685).  Saving model ...\n",
            "Epoch: 571 \tTraining Loss: 0.032145 \tValidation Loss: 0.084630\n",
            "Validation loss decreased (0.084685 --> 0.084630).  Saving model ...\n",
            "Epoch: 572 \tTraining Loss: 0.032135 \tValidation Loss: 0.084575\n",
            "Validation loss decreased (0.084630 --> 0.084575).  Saving model ...\n",
            "Epoch: 573 \tTraining Loss: 0.032125 \tValidation Loss: 0.084521\n",
            "Validation loss decreased (0.084575 --> 0.084521).  Saving model ...\n",
            "Epoch: 574 \tTraining Loss: 0.032115 \tValidation Loss: 0.084468\n",
            "Validation loss decreased (0.084521 --> 0.084468).  Saving model ...\n",
            "Epoch: 575 \tTraining Loss: 0.032104 \tValidation Loss: 0.084415\n",
            "Validation loss decreased (0.084468 --> 0.084415).  Saving model ...\n",
            "Epoch: 576 \tTraining Loss: 0.032094 \tValidation Loss: 0.084363\n",
            "Validation loss decreased (0.084415 --> 0.084363).  Saving model ...\n",
            "Epoch: 577 \tTraining Loss: 0.032084 \tValidation Loss: 0.084312\n",
            "Validation loss decreased (0.084363 --> 0.084312).  Saving model ...\n",
            "Epoch: 578 \tTraining Loss: 0.032074 \tValidation Loss: 0.084261\n",
            "Validation loss decreased (0.084312 --> 0.084261).  Saving model ...\n",
            "Epoch: 579 \tTraining Loss: 0.032064 \tValidation Loss: 0.084211\n",
            "Validation loss decreased (0.084261 --> 0.084211).  Saving model ...\n",
            "Epoch: 580 \tTraining Loss: 0.032054 \tValidation Loss: 0.084162\n",
            "Validation loss decreased (0.084211 --> 0.084162).  Saving model ...\n",
            "Epoch: 581 \tTraining Loss: 0.032044 \tValidation Loss: 0.084114\n",
            "Validation loss decreased (0.084162 --> 0.084114).  Saving model ...\n",
            "Epoch: 582 \tTraining Loss: 0.032034 \tValidation Loss: 0.084066\n",
            "Validation loss decreased (0.084114 --> 0.084066).  Saving model ...\n",
            "Epoch: 583 \tTraining Loss: 0.032024 \tValidation Loss: 0.084019\n",
            "Validation loss decreased (0.084066 --> 0.084019).  Saving model ...\n",
            "Epoch: 584 \tTraining Loss: 0.032014 \tValidation Loss: 0.083973\n",
            "Validation loss decreased (0.084019 --> 0.083973).  Saving model ...\n",
            "Epoch: 585 \tTraining Loss: 0.032005 \tValidation Loss: 0.083928\n",
            "Validation loss decreased (0.083973 --> 0.083928).  Saving model ...\n",
            "Epoch: 586 \tTraining Loss: 0.031995 \tValidation Loss: 0.083883\n",
            "Validation loss decreased (0.083928 --> 0.083883).  Saving model ...\n",
            "Epoch: 587 \tTraining Loss: 0.031985 \tValidation Loss: 0.083838\n",
            "Validation loss decreased (0.083883 --> 0.083838).  Saving model ...\n",
            "Epoch: 588 \tTraining Loss: 0.031976 \tValidation Loss: 0.083795\n",
            "Validation loss decreased (0.083838 --> 0.083795).  Saving model ...\n",
            "Epoch: 589 \tTraining Loss: 0.031966 \tValidation Loss: 0.083751\n",
            "Validation loss decreased (0.083795 --> 0.083751).  Saving model ...\n",
            "Epoch: 590 \tTraining Loss: 0.031956 \tValidation Loss: 0.083709\n",
            "Validation loss decreased (0.083751 --> 0.083709).  Saving model ...\n",
            "Epoch: 591 \tTraining Loss: 0.031947 \tValidation Loss: 0.083668\n",
            "Validation loss decreased (0.083709 --> 0.083668).  Saving model ...\n",
            "Epoch: 592 \tTraining Loss: 0.031937 \tValidation Loss: 0.083627\n",
            "Validation loss decreased (0.083668 --> 0.083627).  Saving model ...\n",
            "Epoch: 593 \tTraining Loss: 0.031928 \tValidation Loss: 0.083586\n",
            "Validation loss decreased (0.083627 --> 0.083586).  Saving model ...\n",
            "Epoch: 594 \tTraining Loss: 0.031919 \tValidation Loss: 0.083547\n",
            "Validation loss decreased (0.083586 --> 0.083547).  Saving model ...\n",
            "Epoch: 595 \tTraining Loss: 0.031909 \tValidation Loss: 0.083508\n",
            "Validation loss decreased (0.083547 --> 0.083508).  Saving model ...\n",
            "Epoch: 596 \tTraining Loss: 0.031900 \tValidation Loss: 0.083469\n",
            "Validation loss decreased (0.083508 --> 0.083469).  Saving model ...\n",
            "Epoch: 597 \tTraining Loss: 0.031891 \tValidation Loss: 0.083432\n",
            "Validation loss decreased (0.083469 --> 0.083432).  Saving model ...\n",
            "Epoch: 598 \tTraining Loss: 0.031881 \tValidation Loss: 0.083395\n",
            "Validation loss decreased (0.083432 --> 0.083395).  Saving model ...\n",
            "Epoch: 599 \tTraining Loss: 0.031872 \tValidation Loss: 0.083358\n",
            "Validation loss decreased (0.083395 --> 0.083358).  Saving model ...\n",
            "Epoch: 600 \tTraining Loss: 0.031863 \tValidation Loss: 0.083322\n",
            "Validation loss decreased (0.083358 --> 0.083322).  Saving model ...\n",
            "Epoch: 601 \tTraining Loss: 0.031854 \tValidation Loss: 0.083286\n",
            "Validation loss decreased (0.083322 --> 0.083286).  Saving model ...\n",
            "Epoch: 602 \tTraining Loss: 0.031845 \tValidation Loss: 0.083252\n",
            "Validation loss decreased (0.083286 --> 0.083252).  Saving model ...\n",
            "Epoch: 603 \tTraining Loss: 0.031836 \tValidation Loss: 0.083218\n",
            "Validation loss decreased (0.083252 --> 0.083218).  Saving model ...\n",
            "Epoch: 604 \tTraining Loss: 0.031827 \tValidation Loss: 0.083184\n",
            "Validation loss decreased (0.083218 --> 0.083184).  Saving model ...\n",
            "Epoch: 605 \tTraining Loss: 0.031818 \tValidation Loss: 0.083151\n",
            "Validation loss decreased (0.083184 --> 0.083151).  Saving model ...\n",
            "Epoch: 606 \tTraining Loss: 0.031809 \tValidation Loss: 0.083118\n",
            "Validation loss decreased (0.083151 --> 0.083118).  Saving model ...\n",
            "Epoch: 607 \tTraining Loss: 0.031800 \tValidation Loss: 0.083087\n",
            "Validation loss decreased (0.083118 --> 0.083087).  Saving model ...\n",
            "Epoch: 608 \tTraining Loss: 0.031791 \tValidation Loss: 0.083055\n",
            "Validation loss decreased (0.083087 --> 0.083055).  Saving model ...\n",
            "Epoch: 609 \tTraining Loss: 0.031783 \tValidation Loss: 0.083024\n",
            "Validation loss decreased (0.083055 --> 0.083024).  Saving model ...\n",
            "Epoch: 610 \tTraining Loss: 0.031774 \tValidation Loss: 0.082994\n",
            "Validation loss decreased (0.083024 --> 0.082994).  Saving model ...\n",
            "Epoch: 611 \tTraining Loss: 0.031765 \tValidation Loss: 0.082965\n",
            "Validation loss decreased (0.082994 --> 0.082965).  Saving model ...\n",
            "Epoch: 612 \tTraining Loss: 0.031756 \tValidation Loss: 0.082936\n",
            "Validation loss decreased (0.082965 --> 0.082936).  Saving model ...\n",
            "Epoch: 613 \tTraining Loss: 0.031748 \tValidation Loss: 0.082907\n",
            "Validation loss decreased (0.082936 --> 0.082907).  Saving model ...\n",
            "Epoch: 614 \tTraining Loss: 0.031739 \tValidation Loss: 0.082879\n",
            "Validation loss decreased (0.082907 --> 0.082879).  Saving model ...\n",
            "Epoch: 615 \tTraining Loss: 0.031731 \tValidation Loss: 0.082851\n",
            "Validation loss decreased (0.082879 --> 0.082851).  Saving model ...\n",
            "Epoch: 616 \tTraining Loss: 0.031722 \tValidation Loss: 0.082824\n",
            "Validation loss decreased (0.082851 --> 0.082824).  Saving model ...\n",
            "Epoch: 617 \tTraining Loss: 0.031714 \tValidation Loss: 0.082798\n",
            "Validation loss decreased (0.082824 --> 0.082798).  Saving model ...\n",
            "Epoch: 618 \tTraining Loss: 0.031705 \tValidation Loss: 0.082772\n",
            "Validation loss decreased (0.082798 --> 0.082772).  Saving model ...\n",
            "Epoch: 619 \tTraining Loss: 0.031697 \tValidation Loss: 0.082747\n",
            "Validation loss decreased (0.082772 --> 0.082747).  Saving model ...\n",
            "Epoch: 620 \tTraining Loss: 0.031688 \tValidation Loss: 0.082722\n",
            "Validation loss decreased (0.082747 --> 0.082722).  Saving model ...\n",
            "Epoch: 621 \tTraining Loss: 0.031680 \tValidation Loss: 0.082697\n",
            "Validation loss decreased (0.082722 --> 0.082697).  Saving model ...\n",
            "Epoch: 622 \tTraining Loss: 0.031672 \tValidation Loss: 0.082673\n",
            "Validation loss decreased (0.082697 --> 0.082673).  Saving model ...\n",
            "Epoch: 623 \tTraining Loss: 0.031663 \tValidation Loss: 0.082650\n",
            "Validation loss decreased (0.082673 --> 0.082650).  Saving model ...\n",
            "Epoch: 624 \tTraining Loss: 0.031655 \tValidation Loss: 0.082627\n",
            "Validation loss decreased (0.082650 --> 0.082627).  Saving model ...\n",
            "Epoch: 625 \tTraining Loss: 0.031647 \tValidation Loss: 0.082605\n",
            "Validation loss decreased (0.082627 --> 0.082605).  Saving model ...\n",
            "Epoch: 626 \tTraining Loss: 0.031639 \tValidation Loss: 0.082583\n",
            "Validation loss decreased (0.082605 --> 0.082583).  Saving model ...\n",
            "Epoch: 627 \tTraining Loss: 0.031631 \tValidation Loss: 0.082561\n",
            "Validation loss decreased (0.082583 --> 0.082561).  Saving model ...\n",
            "Epoch: 628 \tTraining Loss: 0.031623 \tValidation Loss: 0.082540\n",
            "Validation loss decreased (0.082561 --> 0.082540).  Saving model ...\n",
            "Epoch: 629 \tTraining Loss: 0.031615 \tValidation Loss: 0.082519\n",
            "Validation loss decreased (0.082540 --> 0.082519).  Saving model ...\n",
            "Epoch: 630 \tTraining Loss: 0.031607 \tValidation Loss: 0.082499\n",
            "Validation loss decreased (0.082519 --> 0.082499).  Saving model ...\n",
            "Epoch: 631 \tTraining Loss: 0.031599 \tValidation Loss: 0.082480\n",
            "Validation loss decreased (0.082499 --> 0.082480).  Saving model ...\n",
            "Epoch: 632 \tTraining Loss: 0.031591 \tValidation Loss: 0.082461\n",
            "Validation loss decreased (0.082480 --> 0.082461).  Saving model ...\n",
            "Epoch: 633 \tTraining Loss: 0.031583 \tValidation Loss: 0.082442\n",
            "Validation loss decreased (0.082461 --> 0.082442).  Saving model ...\n",
            "Epoch: 634 \tTraining Loss: 0.031575 \tValidation Loss: 0.082423\n",
            "Validation loss decreased (0.082442 --> 0.082423).  Saving model ...\n",
            "Epoch: 635 \tTraining Loss: 0.031567 \tValidation Loss: 0.082405\n",
            "Validation loss decreased (0.082423 --> 0.082405).  Saving model ...\n",
            "Epoch: 636 \tTraining Loss: 0.031559 \tValidation Loss: 0.082388\n",
            "Validation loss decreased (0.082405 --> 0.082388).  Saving model ...\n",
            "Epoch: 637 \tTraining Loss: 0.031551 \tValidation Loss: 0.082371\n",
            "Validation loss decreased (0.082388 --> 0.082371).  Saving model ...\n",
            "Epoch: 638 \tTraining Loss: 0.031543 \tValidation Loss: 0.082354\n",
            "Validation loss decreased (0.082371 --> 0.082354).  Saving model ...\n",
            "Epoch: 639 \tTraining Loss: 0.031536 \tValidation Loss: 0.082338\n",
            "Validation loss decreased (0.082354 --> 0.082338).  Saving model ...\n",
            "Epoch: 640 \tTraining Loss: 0.031528 \tValidation Loss: 0.082322\n",
            "Validation loss decreased (0.082338 --> 0.082322).  Saving model ...\n",
            "Epoch: 641 \tTraining Loss: 0.031520 \tValidation Loss: 0.082308\n",
            "Validation loss decreased (0.082322 --> 0.082308).  Saving model ...\n",
            "Epoch: 642 \tTraining Loss: 0.031513 \tValidation Loss: 0.082293\n",
            "Validation loss decreased (0.082308 --> 0.082293).  Saving model ...\n",
            "Epoch: 643 \tTraining Loss: 0.031505 \tValidation Loss: 0.082279\n",
            "Validation loss decreased (0.082293 --> 0.082279).  Saving model ...\n",
            "Epoch: 644 \tTraining Loss: 0.031497 \tValidation Loss: 0.082265\n",
            "Validation loss decreased (0.082279 --> 0.082265).  Saving model ...\n",
            "Epoch: 645 \tTraining Loss: 0.031490 \tValidation Loss: 0.082252\n",
            "Validation loss decreased (0.082265 --> 0.082252).  Saving model ...\n",
            "Epoch: 646 \tTraining Loss: 0.031482 \tValidation Loss: 0.082239\n",
            "Validation loss decreased (0.082252 --> 0.082239).  Saving model ...\n",
            "Epoch: 647 \tTraining Loss: 0.031475 \tValidation Loss: 0.082226\n",
            "Validation loss decreased (0.082239 --> 0.082226).  Saving model ...\n",
            "Epoch: 648 \tTraining Loss: 0.031467 \tValidation Loss: 0.082214\n",
            "Validation loss decreased (0.082226 --> 0.082214).  Saving model ...\n",
            "Epoch: 649 \tTraining Loss: 0.031460 \tValidation Loss: 0.082203\n",
            "Validation loss decreased (0.082214 --> 0.082203).  Saving model ...\n",
            "Epoch: 650 \tTraining Loss: 0.031452 \tValidation Loss: 0.082191\n",
            "Validation loss decreased (0.082203 --> 0.082191).  Saving model ...\n",
            "Epoch: 651 \tTraining Loss: 0.031445 \tValidation Loss: 0.082180\n",
            "Validation loss decreased (0.082191 --> 0.082180).  Saving model ...\n",
            "Epoch: 652 \tTraining Loss: 0.031438 \tValidation Loss: 0.082170\n",
            "Validation loss decreased (0.082180 --> 0.082170).  Saving model ...\n",
            "Epoch: 653 \tTraining Loss: 0.031430 \tValidation Loss: 0.082159\n",
            "Validation loss decreased (0.082170 --> 0.082159).  Saving model ...\n",
            "Epoch: 654 \tTraining Loss: 0.031423 \tValidation Loss: 0.082150\n",
            "Validation loss decreased (0.082159 --> 0.082150).  Saving model ...\n",
            "Epoch: 655 \tTraining Loss: 0.031416 \tValidation Loss: 0.082141\n",
            "Validation loss decreased (0.082150 --> 0.082141).  Saving model ...\n",
            "Epoch: 656 \tTraining Loss: 0.031409 \tValidation Loss: 0.082132\n",
            "Validation loss decreased (0.082141 --> 0.082132).  Saving model ...\n",
            "Epoch: 657 \tTraining Loss: 0.031401 \tValidation Loss: 0.082124\n",
            "Validation loss decreased (0.082132 --> 0.082124).  Saving model ...\n",
            "Epoch: 658 \tTraining Loss: 0.031394 \tValidation Loss: 0.082115\n",
            "Validation loss decreased (0.082124 --> 0.082115).  Saving model ...\n",
            "Epoch: 659 \tTraining Loss: 0.031387 \tValidation Loss: 0.082108\n",
            "Validation loss decreased (0.082115 --> 0.082108).  Saving model ...\n",
            "Epoch: 660 \tTraining Loss: 0.031380 \tValidation Loss: 0.082101\n",
            "Validation loss decreased (0.082108 --> 0.082101).  Saving model ...\n",
            "Epoch: 661 \tTraining Loss: 0.031373 \tValidation Loss: 0.082093\n",
            "Validation loss decreased (0.082101 --> 0.082093).  Saving model ...\n",
            "Epoch: 662 \tTraining Loss: 0.031366 \tValidation Loss: 0.082087\n",
            "Validation loss decreased (0.082093 --> 0.082087).  Saving model ...\n",
            "Epoch: 663 \tTraining Loss: 0.031358 \tValidation Loss: 0.082081\n",
            "Validation loss decreased (0.082087 --> 0.082081).  Saving model ...\n",
            "Epoch: 664 \tTraining Loss: 0.031351 \tValidation Loss: 0.082075\n",
            "Validation loss decreased (0.082081 --> 0.082075).  Saving model ...\n",
            "Epoch: 665 \tTraining Loss: 0.031344 \tValidation Loss: 0.082070\n",
            "Validation loss decreased (0.082075 --> 0.082070).  Saving model ...\n",
            "Epoch: 666 \tTraining Loss: 0.031337 \tValidation Loss: 0.082065\n",
            "Validation loss decreased (0.082070 --> 0.082065).  Saving model ...\n",
            "Epoch: 667 \tTraining Loss: 0.031330 \tValidation Loss: 0.082061\n",
            "Validation loss decreased (0.082065 --> 0.082061).  Saving model ...\n",
            "Epoch: 668 \tTraining Loss: 0.031323 \tValidation Loss: 0.082057\n",
            "Validation loss decreased (0.082061 --> 0.082057).  Saving model ...\n",
            "Epoch: 669 \tTraining Loss: 0.031317 \tValidation Loss: 0.082053\n",
            "Validation loss decreased (0.082057 --> 0.082053).  Saving model ...\n",
            "Epoch: 670 \tTraining Loss: 0.031310 \tValidation Loss: 0.082049\n",
            "Validation loss decreased (0.082053 --> 0.082049).  Saving model ...\n",
            "Epoch: 671 \tTraining Loss: 0.031303 \tValidation Loss: 0.082046\n",
            "Validation loss decreased (0.082049 --> 0.082046).  Saving model ...\n",
            "Epoch: 672 \tTraining Loss: 0.031296 \tValidation Loss: 0.082044\n",
            "Validation loss decreased (0.082046 --> 0.082044).  Saving model ...\n",
            "Epoch: 673 \tTraining Loss: 0.031289 \tValidation Loss: 0.082042\n",
            "Validation loss decreased (0.082044 --> 0.082042).  Saving model ...\n",
            "Epoch: 674 \tTraining Loss: 0.031282 \tValidation Loss: 0.082039\n",
            "Validation loss decreased (0.082042 --> 0.082039).  Saving model ...\n",
            "Epoch: 675 \tTraining Loss: 0.031276 \tValidation Loss: 0.082038\n",
            "Validation loss decreased (0.082039 --> 0.082038).  Saving model ...\n",
            "Epoch: 676 \tTraining Loss: 0.031269 \tValidation Loss: 0.082037\n",
            "Validation loss decreased (0.082038 --> 0.082037).  Saving model ...\n",
            "Epoch: 677 \tTraining Loss: 0.031262 \tValidation Loss: 0.082036\n",
            "Validation loss decreased (0.082037 --> 0.082036).  Saving model ...\n",
            "Epoch: 678 \tTraining Loss: 0.031255 \tValidation Loss: 0.082035\n",
            "Validation loss decreased (0.082036 --> 0.082035).  Saving model ...\n",
            "Epoch: 679 \tTraining Loss: 0.031249 \tValidation Loss: 0.082035\n",
            "Validation loss decreased (0.082035 --> 0.082035).  Saving model ...\n",
            "Epoch: 680 \tTraining Loss: 0.031242 \tValidation Loss: 0.082035\n",
            "Epoch: 681 \tTraining Loss: 0.031235 \tValidation Loss: 0.082036\n",
            "Epoch: 682 \tTraining Loss: 0.031229 \tValidation Loss: 0.082037\n",
            "Epoch: 683 \tTraining Loss: 0.031222 \tValidation Loss: 0.082038\n",
            "Epoch: 684 \tTraining Loss: 0.031215 \tValidation Loss: 0.082039\n",
            "Epoch: 685 \tTraining Loss: 0.031209 \tValidation Loss: 0.082042\n",
            "Epoch: 686 \tTraining Loss: 0.031202 \tValidation Loss: 0.082044\n",
            "Epoch: 687 \tTraining Loss: 0.031196 \tValidation Loss: 0.082046\n",
            "Epoch: 688 \tTraining Loss: 0.031189 \tValidation Loss: 0.082049\n",
            "Epoch: 689 \tTraining Loss: 0.031183 \tValidation Loss: 0.082052\n",
            "Epoch: 690 \tTraining Loss: 0.031176 \tValidation Loss: 0.082055\n",
            "Epoch: 691 \tTraining Loss: 0.031170 \tValidation Loss: 0.082059\n",
            "Epoch: 692 \tTraining Loss: 0.031164 \tValidation Loss: 0.082063\n",
            "Epoch: 693 \tTraining Loss: 0.031157 \tValidation Loss: 0.082067\n",
            "Epoch: 694 \tTraining Loss: 0.031151 \tValidation Loss: 0.082072\n",
            "Epoch: 695 \tTraining Loss: 0.031144 \tValidation Loss: 0.082077\n",
            "Epoch: 696 \tTraining Loss: 0.031138 \tValidation Loss: 0.082082\n",
            "Epoch: 697 \tTraining Loss: 0.031132 \tValidation Loss: 0.082087\n",
            "Epoch: 698 \tTraining Loss: 0.031126 \tValidation Loss: 0.082093\n",
            "Epoch: 699 \tTraining Loss: 0.031119 \tValidation Loss: 0.082099\n",
            "Epoch: 700 \tTraining Loss: 0.031113 \tValidation Loss: 0.082105\n",
            "Epoch: 701 \tTraining Loss: 0.031107 \tValidation Loss: 0.082111\n",
            "Epoch: 702 \tTraining Loss: 0.031101 \tValidation Loss: 0.082118\n",
            "Epoch: 703 \tTraining Loss: 0.031094 \tValidation Loss: 0.082125\n",
            "Epoch: 704 \tTraining Loss: 0.031088 \tValidation Loss: 0.082132\n",
            "Epoch: 705 \tTraining Loss: 0.031082 \tValidation Loss: 0.082140\n",
            "Epoch: 706 \tTraining Loss: 0.031076 \tValidation Loss: 0.082148\n",
            "Epoch: 707 \tTraining Loss: 0.031070 \tValidation Loss: 0.082156\n",
            "Epoch: 708 \tTraining Loss: 0.031064 \tValidation Loss: 0.082164\n",
            "Epoch: 709 \tTraining Loss: 0.031057 \tValidation Loss: 0.082172\n",
            "Epoch: 710 \tTraining Loss: 0.031051 \tValidation Loss: 0.082181\n",
            "Epoch: 711 \tTraining Loss: 0.031045 \tValidation Loss: 0.082190\n",
            "Epoch: 712 \tTraining Loss: 0.031039 \tValidation Loss: 0.082199\n",
            "Epoch: 713 \tTraining Loss: 0.031033 \tValidation Loss: 0.082208\n",
            "Epoch: 714 \tTraining Loss: 0.031027 \tValidation Loss: 0.082218\n",
            "Epoch: 715 \tTraining Loss: 0.031021 \tValidation Loss: 0.082228\n",
            "Epoch: 716 \tTraining Loss: 0.031015 \tValidation Loss: 0.082237\n",
            "Epoch: 717 \tTraining Loss: 0.031009 \tValidation Loss: 0.082247\n",
            "Epoch: 718 \tTraining Loss: 0.031003 \tValidation Loss: 0.082257\n",
            "Epoch: 719 \tTraining Loss: 0.030997 \tValidation Loss: 0.082268\n",
            "Epoch: 720 \tTraining Loss: 0.030992 \tValidation Loss: 0.082278\n",
            "Epoch: 721 \tTraining Loss: 0.030986 \tValidation Loss: 0.082289\n",
            "Epoch: 722 \tTraining Loss: 0.030980 \tValidation Loss: 0.082300\n",
            "Epoch: 723 \tTraining Loss: 0.030974 \tValidation Loss: 0.082311\n",
            "Epoch: 724 \tTraining Loss: 0.030968 \tValidation Loss: 0.082322\n",
            "Epoch: 725 \tTraining Loss: 0.030962 \tValidation Loss: 0.082333\n",
            "Epoch: 726 \tTraining Loss: 0.030956 \tValidation Loss: 0.082344\n",
            "Epoch: 727 \tTraining Loss: 0.030951 \tValidation Loss: 0.082356\n",
            "Epoch: 728 \tTraining Loss: 0.030945 \tValidation Loss: 0.082367\n",
            "Epoch: 729 \tTraining Loss: 0.030939 \tValidation Loss: 0.082379\n",
            "Epoch: 730 \tTraining Loss: 0.030933 \tValidation Loss: 0.082390\n",
            "Epoch: 731 \tTraining Loss: 0.030928 \tValidation Loss: 0.082402\n",
            "Epoch: 732 \tTraining Loss: 0.030922 \tValidation Loss: 0.082415\n",
            "Epoch: 733 \tTraining Loss: 0.030916 \tValidation Loss: 0.082427\n",
            "Epoch: 734 \tTraining Loss: 0.030911 \tValidation Loss: 0.082439\n",
            "Epoch: 735 \tTraining Loss: 0.030905 \tValidation Loss: 0.082450\n",
            "Epoch: 736 \tTraining Loss: 0.030899 \tValidation Loss: 0.082462\n",
            "Epoch: 737 \tTraining Loss: 0.030894 \tValidation Loss: 0.082475\n",
            "Epoch: 738 \tTraining Loss: 0.030888 \tValidation Loss: 0.082487\n",
            "Epoch: 739 \tTraining Loss: 0.030882 \tValidation Loss: 0.082499\n",
            "Epoch: 740 \tTraining Loss: 0.030877 \tValidation Loss: 0.082512\n",
            "Epoch: 741 \tTraining Loss: 0.030871 \tValidation Loss: 0.082524\n",
            "Epoch: 742 \tTraining Loss: 0.030866 \tValidation Loss: 0.082537\n",
            "Epoch: 743 \tTraining Loss: 0.030860 \tValidation Loss: 0.082550\n",
            "Epoch: 744 \tTraining Loss: 0.030854 \tValidation Loss: 0.082562\n",
            "Epoch: 745 \tTraining Loss: 0.030849 \tValidation Loss: 0.082575\n",
            "Epoch: 746 \tTraining Loss: 0.030843 \tValidation Loss: 0.082587\n",
            "Epoch: 747 \tTraining Loss: 0.030838 \tValidation Loss: 0.082600\n",
            "Epoch: 748 \tTraining Loss: 0.030832 \tValidation Loss: 0.082612\n",
            "Epoch: 749 \tTraining Loss: 0.030827 \tValidation Loss: 0.082625\n",
            "Epoch: 750 \tTraining Loss: 0.030821 \tValidation Loss: 0.082637\n",
            "Epoch: 751 \tTraining Loss: 0.030816 \tValidation Loss: 0.082649\n",
            "Epoch: 752 \tTraining Loss: 0.030811 \tValidation Loss: 0.082662\n",
            "Epoch: 753 \tTraining Loss: 0.030805 \tValidation Loss: 0.082674\n",
            "Epoch: 754 \tTraining Loss: 0.030800 \tValidation Loss: 0.082686\n",
            "Epoch: 755 \tTraining Loss: 0.030794 \tValidation Loss: 0.082699\n",
            "Epoch: 756 \tTraining Loss: 0.030789 \tValidation Loss: 0.082711\n",
            "Epoch: 757 \tTraining Loss: 0.030784 \tValidation Loss: 0.082723\n",
            "Epoch: 758 \tTraining Loss: 0.030778 \tValidation Loss: 0.082736\n",
            "Epoch: 759 \tTraining Loss: 0.030773 \tValidation Loss: 0.082747\n",
            "Epoch: 760 \tTraining Loss: 0.030767 \tValidation Loss: 0.082759\n",
            "Epoch: 761 \tTraining Loss: 0.030762 \tValidation Loss: 0.082772\n",
            "Epoch: 762 \tTraining Loss: 0.030757 \tValidation Loss: 0.082783\n",
            "Epoch: 763 \tTraining Loss: 0.030752 \tValidation Loss: 0.082794\n",
            "Epoch: 764 \tTraining Loss: 0.030746 \tValidation Loss: 0.082806\n",
            "Epoch: 765 \tTraining Loss: 0.030741 \tValidation Loss: 0.082818\n",
            "Epoch: 766 \tTraining Loss: 0.030736 \tValidation Loss: 0.082830\n",
            "Epoch: 767 \tTraining Loss: 0.030730 \tValidation Loss: 0.082841\n",
            "Epoch: 768 \tTraining Loss: 0.030725 \tValidation Loss: 0.082852\n",
            "Epoch: 769 \tTraining Loss: 0.030720 \tValidation Loss: 0.082863\n",
            "Epoch: 770 \tTraining Loss: 0.030715 \tValidation Loss: 0.082874\n",
            "Epoch: 771 \tTraining Loss: 0.030710 \tValidation Loss: 0.082885\n",
            "Epoch: 772 \tTraining Loss: 0.030704 \tValidation Loss: 0.082896\n",
            "Epoch: 773 \tTraining Loss: 0.030699 \tValidation Loss: 0.082906\n",
            "Epoch: 774 \tTraining Loss: 0.030694 \tValidation Loss: 0.082916\n",
            "Epoch: 775 \tTraining Loss: 0.030689 \tValidation Loss: 0.082927\n",
            "Epoch: 776 \tTraining Loss: 0.030684 \tValidation Loss: 0.082937\n",
            "Epoch: 777 \tTraining Loss: 0.030679 \tValidation Loss: 0.082947\n",
            "Epoch: 778 \tTraining Loss: 0.030673 \tValidation Loss: 0.082957\n",
            "Epoch: 779 \tTraining Loss: 0.030668 \tValidation Loss: 0.082967\n",
            "Epoch: 780 \tTraining Loss: 0.030663 \tValidation Loss: 0.082976\n",
            "Epoch: 781 \tTraining Loss: 0.030658 \tValidation Loss: 0.082985\n",
            "Epoch: 782 \tTraining Loss: 0.030653 \tValidation Loss: 0.082995\n",
            "Epoch: 783 \tTraining Loss: 0.030648 \tValidation Loss: 0.083004\n",
            "Epoch: 784 \tTraining Loss: 0.030643 \tValidation Loss: 0.083013\n",
            "Epoch: 785 \tTraining Loss: 0.030638 \tValidation Loss: 0.083022\n",
            "Epoch: 786 \tTraining Loss: 0.030633 \tValidation Loss: 0.083031\n",
            "Epoch: 787 \tTraining Loss: 0.030628 \tValidation Loss: 0.083039\n",
            "Epoch: 788 \tTraining Loss: 0.030623 \tValidation Loss: 0.083047\n",
            "Epoch: 789 \tTraining Loss: 0.030618 \tValidation Loss: 0.083056\n",
            "Epoch: 790 \tTraining Loss: 0.030613 \tValidation Loss: 0.083064\n",
            "Epoch: 791 \tTraining Loss: 0.030608 \tValidation Loss: 0.083071\n",
            "Epoch: 792 \tTraining Loss: 0.030603 \tValidation Loss: 0.083079\n",
            "Epoch: 793 \tTraining Loss: 0.030598 \tValidation Loss: 0.083087\n",
            "Epoch: 794 \tTraining Loss: 0.030593 \tValidation Loss: 0.083094\n",
            "Epoch: 795 \tTraining Loss: 0.030588 \tValidation Loss: 0.083101\n",
            "Epoch: 796 \tTraining Loss: 0.030583 \tValidation Loss: 0.083108\n",
            "Epoch: 797 \tTraining Loss: 0.030578 \tValidation Loss: 0.083115\n",
            "Epoch: 798 \tTraining Loss: 0.030573 \tValidation Loss: 0.083122\n",
            "Epoch: 799 \tTraining Loss: 0.030568 \tValidation Loss: 0.083128\n",
            "Epoch: 800 \tTraining Loss: 0.030563 \tValidation Loss: 0.083135\n",
            "Epoch: 801 \tTraining Loss: 0.030558 \tValidation Loss: 0.083141\n",
            "Epoch: 802 \tTraining Loss: 0.030553 \tValidation Loss: 0.083147\n",
            "Epoch: 803 \tTraining Loss: 0.030549 \tValidation Loss: 0.083152\n",
            "Epoch: 804 \tTraining Loss: 0.030544 \tValidation Loss: 0.083158\n",
            "Epoch: 805 \tTraining Loss: 0.030539 \tValidation Loss: 0.083164\n",
            "Epoch: 806 \tTraining Loss: 0.030534 \tValidation Loss: 0.083169\n",
            "Epoch: 807 \tTraining Loss: 0.030529 \tValidation Loss: 0.083174\n",
            "Epoch: 808 \tTraining Loss: 0.030524 \tValidation Loss: 0.083179\n",
            "Epoch: 809 \tTraining Loss: 0.030519 \tValidation Loss: 0.083183\n",
            "Epoch: 810 \tTraining Loss: 0.030515 \tValidation Loss: 0.083188\n",
            "Epoch: 811 \tTraining Loss: 0.030510 \tValidation Loss: 0.083192\n",
            "Epoch: 812 \tTraining Loss: 0.030505 \tValidation Loss: 0.083197\n",
            "Epoch: 813 \tTraining Loss: 0.030500 \tValidation Loss: 0.083200\n",
            "Epoch: 814 \tTraining Loss: 0.030495 \tValidation Loss: 0.083204\n",
            "Epoch: 815 \tTraining Loss: 0.030491 \tValidation Loss: 0.083208\n",
            "Epoch: 816 \tTraining Loss: 0.030486 \tValidation Loss: 0.083212\n",
            "Epoch: 817 \tTraining Loss: 0.030481 \tValidation Loss: 0.083215\n",
            "Epoch: 818 \tTraining Loss: 0.030476 \tValidation Loss: 0.083218\n",
            "Epoch: 819 \tTraining Loss: 0.030472 \tValidation Loss: 0.083221\n",
            "Epoch: 820 \tTraining Loss: 0.030467 \tValidation Loss: 0.083224\n",
            "Epoch: 821 \tTraining Loss: 0.030462 \tValidation Loss: 0.083227\n",
            "Epoch: 822 \tTraining Loss: 0.030457 \tValidation Loss: 0.083230\n",
            "Epoch: 823 \tTraining Loss: 0.030453 \tValidation Loss: 0.083232\n",
            "Epoch: 824 \tTraining Loss: 0.030448 \tValidation Loss: 0.083234\n",
            "Epoch: 825 \tTraining Loss: 0.030443 \tValidation Loss: 0.083236\n",
            "Epoch: 826 \tTraining Loss: 0.030439 \tValidation Loss: 0.083239\n",
            "Epoch: 827 \tTraining Loss: 0.030434 \tValidation Loss: 0.083240\n",
            "Epoch: 828 \tTraining Loss: 0.030429 \tValidation Loss: 0.083242\n",
            "Epoch: 829 \tTraining Loss: 0.030425 \tValidation Loss: 0.083243\n",
            "Epoch: 830 \tTraining Loss: 0.030420 \tValidation Loss: 0.083244\n",
            "Epoch: 831 \tTraining Loss: 0.030415 \tValidation Loss: 0.083246\n",
            "Epoch: 832 \tTraining Loss: 0.030411 \tValidation Loss: 0.083247\n",
            "Epoch: 833 \tTraining Loss: 0.030406 \tValidation Loss: 0.083248\n",
            "Epoch: 834 \tTraining Loss: 0.030401 \tValidation Loss: 0.083249\n",
            "Epoch: 835 \tTraining Loss: 0.030397 \tValidation Loss: 0.083250\n",
            "Epoch: 836 \tTraining Loss: 0.030392 \tValidation Loss: 0.083250\n",
            "Epoch: 837 \tTraining Loss: 0.030387 \tValidation Loss: 0.083251\n",
            "Epoch: 838 \tTraining Loss: 0.030383 \tValidation Loss: 0.083251\n",
            "Epoch: 839 \tTraining Loss: 0.030378 \tValidation Loss: 0.083251\n",
            "Epoch: 840 \tTraining Loss: 0.030373 \tValidation Loss: 0.083251\n",
            "Epoch: 841 \tTraining Loss: 0.030369 \tValidation Loss: 0.083252\n",
            "Epoch: 842 \tTraining Loss: 0.030364 \tValidation Loss: 0.083251\n",
            "Epoch: 843 \tTraining Loss: 0.030360 \tValidation Loss: 0.083251\n",
            "Epoch: 844 \tTraining Loss: 0.030355 \tValidation Loss: 0.083251\n",
            "Epoch: 845 \tTraining Loss: 0.030351 \tValidation Loss: 0.083250\n",
            "Epoch: 846 \tTraining Loss: 0.030346 \tValidation Loss: 0.083250\n",
            "Epoch: 847 \tTraining Loss: 0.030341 \tValidation Loss: 0.083249\n",
            "Epoch: 848 \tTraining Loss: 0.030337 \tValidation Loss: 0.083249\n",
            "Epoch: 849 \tTraining Loss: 0.030332 \tValidation Loss: 0.083248\n",
            "Epoch: 850 \tTraining Loss: 0.030328 \tValidation Loss: 0.083247\n",
            "Epoch: 851 \tTraining Loss: 0.030323 \tValidation Loss: 0.083246\n",
            "Epoch: 852 \tTraining Loss: 0.030319 \tValidation Loss: 0.083245\n",
            "Epoch: 853 \tTraining Loss: 0.030314 \tValidation Loss: 0.083244\n",
            "Epoch: 854 \tTraining Loss: 0.030310 \tValidation Loss: 0.083244\n",
            "Epoch: 855 \tTraining Loss: 0.030305 \tValidation Loss: 0.083242\n",
            "Epoch: 856 \tTraining Loss: 0.030301 \tValidation Loss: 0.083241\n",
            "Epoch: 857 \tTraining Loss: 0.030296 \tValidation Loss: 0.083240\n",
            "Epoch: 858 \tTraining Loss: 0.030292 \tValidation Loss: 0.083239\n",
            "Epoch: 859 \tTraining Loss: 0.030287 \tValidation Loss: 0.083237\n",
            "Epoch: 860 \tTraining Loss: 0.030283 \tValidation Loss: 0.083236\n",
            "Epoch: 861 \tTraining Loss: 0.030278 \tValidation Loss: 0.083234\n",
            "Epoch: 862 \tTraining Loss: 0.030274 \tValidation Loss: 0.083233\n",
            "Epoch: 863 \tTraining Loss: 0.030269 \tValidation Loss: 0.083231\n",
            "Epoch: 864 \tTraining Loss: 0.030265 \tValidation Loss: 0.083229\n",
            "Epoch: 865 \tTraining Loss: 0.030260 \tValidation Loss: 0.083228\n",
            "Epoch: 866 \tTraining Loss: 0.030256 \tValidation Loss: 0.083226\n",
            "Epoch: 867 \tTraining Loss: 0.030251 \tValidation Loss: 0.083224\n",
            "Epoch: 868 \tTraining Loss: 0.030247 \tValidation Loss: 0.083222\n",
            "Epoch: 869 \tTraining Loss: 0.030243 \tValidation Loss: 0.083220\n",
            "Epoch: 870 \tTraining Loss: 0.030238 \tValidation Loss: 0.083219\n",
            "Epoch: 871 \tTraining Loss: 0.030234 \tValidation Loss: 0.083217\n",
            "Epoch: 872 \tTraining Loss: 0.030229 \tValidation Loss: 0.083214\n",
            "Epoch: 873 \tTraining Loss: 0.030225 \tValidation Loss: 0.083213\n",
            "Epoch: 874 \tTraining Loss: 0.030220 \tValidation Loss: 0.083211\n",
            "Epoch: 875 \tTraining Loss: 0.030216 \tValidation Loss: 0.083208\n",
            "Epoch: 876 \tTraining Loss: 0.030212 \tValidation Loss: 0.083207\n",
            "Epoch: 877 \tTraining Loss: 0.030207 \tValidation Loss: 0.083204\n",
            "Epoch: 878 \tTraining Loss: 0.030203 \tValidation Loss: 0.083202\n",
            "Epoch: 879 \tTraining Loss: 0.030198 \tValidation Loss: 0.083201\n",
            "Epoch: 880 \tTraining Loss: 0.030194 \tValidation Loss: 0.083198\n",
            "Epoch: 881 \tTraining Loss: 0.030190 \tValidation Loss: 0.083196\n",
            "Epoch: 882 \tTraining Loss: 0.030185 \tValidation Loss: 0.083195\n",
            "Epoch: 883 \tTraining Loss: 0.030181 \tValidation Loss: 0.083193\n",
            "Epoch: 884 \tTraining Loss: 0.030177 \tValidation Loss: 0.083191\n",
            "Epoch: 885 \tTraining Loss: 0.030172 \tValidation Loss: 0.083188\n",
            "Epoch: 886 \tTraining Loss: 0.030168 \tValidation Loss: 0.083186\n",
            "Epoch: 887 \tTraining Loss: 0.030163 \tValidation Loss: 0.083184\n",
            "Epoch: 888 \tTraining Loss: 0.030159 \tValidation Loss: 0.083182\n",
            "Epoch: 889 \tTraining Loss: 0.030155 \tValidation Loss: 0.083180\n",
            "Epoch: 890 \tTraining Loss: 0.030150 \tValidation Loss: 0.083178\n",
            "Epoch: 891 \tTraining Loss: 0.030146 \tValidation Loss: 0.083176\n",
            "Epoch: 892 \tTraining Loss: 0.030142 \tValidation Loss: 0.083174\n",
            "Epoch: 893 \tTraining Loss: 0.030137 \tValidation Loss: 0.083172\n",
            "Epoch: 894 \tTraining Loss: 0.030133 \tValidation Loss: 0.083169\n",
            "Epoch: 895 \tTraining Loss: 0.030129 \tValidation Loss: 0.083168\n",
            "Epoch: 896 \tTraining Loss: 0.030124 \tValidation Loss: 0.083165\n",
            "Epoch: 897 \tTraining Loss: 0.030120 \tValidation Loss: 0.083163\n",
            "Epoch: 898 \tTraining Loss: 0.030116 \tValidation Loss: 0.083161\n",
            "Epoch: 899 \tTraining Loss: 0.030111 \tValidation Loss: 0.083159\n",
            "Epoch: 900 \tTraining Loss: 0.030107 \tValidation Loss: 0.083158\n",
            "Epoch: 901 \tTraining Loss: 0.030103 \tValidation Loss: 0.083156\n",
            "Epoch: 902 \tTraining Loss: 0.030098 \tValidation Loss: 0.083154\n",
            "Epoch: 903 \tTraining Loss: 0.030094 \tValidation Loss: 0.083152\n",
            "Epoch: 904 \tTraining Loss: 0.030090 \tValidation Loss: 0.083150\n",
            "Epoch: 905 \tTraining Loss: 0.030085 \tValidation Loss: 0.083148\n",
            "Epoch: 906 \tTraining Loss: 0.030081 \tValidation Loss: 0.083146\n",
            "Epoch: 907 \tTraining Loss: 0.030077 \tValidation Loss: 0.083144\n",
            "Epoch: 908 \tTraining Loss: 0.030072 \tValidation Loss: 0.083142\n",
            "Epoch: 909 \tTraining Loss: 0.030068 \tValidation Loss: 0.083140\n",
            "Epoch: 910 \tTraining Loss: 0.030064 \tValidation Loss: 0.083138\n",
            "Epoch: 911 \tTraining Loss: 0.030059 \tValidation Loss: 0.083137\n",
            "Epoch: 912 \tTraining Loss: 0.030055 \tValidation Loss: 0.083134\n",
            "Epoch: 913 \tTraining Loss: 0.030051 \tValidation Loss: 0.083132\n",
            "Epoch: 914 \tTraining Loss: 0.030046 \tValidation Loss: 0.083130\n",
            "Epoch: 915 \tTraining Loss: 0.030042 \tValidation Loss: 0.083129\n",
            "Epoch: 916 \tTraining Loss: 0.030038 \tValidation Loss: 0.083127\n",
            "Epoch: 917 \tTraining Loss: 0.030033 \tValidation Loss: 0.083125\n",
            "Epoch: 918 \tTraining Loss: 0.030029 \tValidation Loss: 0.083123\n",
            "Epoch: 919 \tTraining Loss: 0.030025 \tValidation Loss: 0.083122\n",
            "Epoch: 920 \tTraining Loss: 0.030020 \tValidation Loss: 0.083120\n",
            "Epoch: 921 \tTraining Loss: 0.030016 \tValidation Loss: 0.083118\n",
            "Epoch: 922 \tTraining Loss: 0.030012 \tValidation Loss: 0.083117\n",
            "Epoch: 923 \tTraining Loss: 0.030007 \tValidation Loss: 0.083115\n",
            "Epoch: 924 \tTraining Loss: 0.030003 \tValidation Loss: 0.083113\n",
            "Epoch: 925 \tTraining Loss: 0.029999 \tValidation Loss: 0.083111\n",
            "Epoch: 926 \tTraining Loss: 0.029994 \tValidation Loss: 0.083109\n",
            "Epoch: 927 \tTraining Loss: 0.029990 \tValidation Loss: 0.083107\n",
            "Epoch: 928 \tTraining Loss: 0.029986 \tValidation Loss: 0.083105\n",
            "Epoch: 929 \tTraining Loss: 0.029981 \tValidation Loss: 0.083104\n",
            "Epoch: 930 \tTraining Loss: 0.029977 \tValidation Loss: 0.083102\n",
            "Epoch: 931 \tTraining Loss: 0.029973 \tValidation Loss: 0.083100\n",
            "Epoch: 932 \tTraining Loss: 0.029968 \tValidation Loss: 0.083098\n",
            "Epoch: 933 \tTraining Loss: 0.029964 \tValidation Loss: 0.083096\n",
            "Epoch: 934 \tTraining Loss: 0.029959 \tValidation Loss: 0.083094\n",
            "Epoch: 935 \tTraining Loss: 0.029955 \tValidation Loss: 0.083092\n",
            "Epoch: 936 \tTraining Loss: 0.029951 \tValidation Loss: 0.083090\n",
            "Epoch: 937 \tTraining Loss: 0.029946 \tValidation Loss: 0.083088\n",
            "Epoch: 938 \tTraining Loss: 0.029942 \tValidation Loss: 0.083086\n",
            "Epoch: 939 \tTraining Loss: 0.029938 \tValidation Loss: 0.083084\n",
            "Epoch: 940 \tTraining Loss: 0.029933 \tValidation Loss: 0.083082\n",
            "Epoch: 941 \tTraining Loss: 0.029929 \tValidation Loss: 0.083080\n",
            "Epoch: 942 \tTraining Loss: 0.029925 \tValidation Loss: 0.083078\n",
            "Epoch: 943 \tTraining Loss: 0.029920 \tValidation Loss: 0.083076\n",
            "Epoch: 944 \tTraining Loss: 0.029916 \tValidation Loss: 0.083073\n",
            "Epoch: 945 \tTraining Loss: 0.029912 \tValidation Loss: 0.083071\n",
            "Epoch: 946 \tTraining Loss: 0.029907 \tValidation Loss: 0.083069\n",
            "Epoch: 947 \tTraining Loss: 0.029903 \tValidation Loss: 0.083066\n",
            "Epoch: 948 \tTraining Loss: 0.029898 \tValidation Loss: 0.083064\n",
            "Epoch: 949 \tTraining Loss: 0.029894 \tValidation Loss: 0.083062\n",
            "Epoch: 950 \tTraining Loss: 0.029890 \tValidation Loss: 0.083059\n",
            "Epoch: 951 \tTraining Loss: 0.029885 \tValidation Loss: 0.083056\n",
            "Epoch: 952 \tTraining Loss: 0.029881 \tValidation Loss: 0.083053\n",
            "Epoch: 953 \tTraining Loss: 0.029876 \tValidation Loss: 0.083050\n",
            "Epoch: 954 \tTraining Loss: 0.029872 \tValidation Loss: 0.083047\n",
            "Epoch: 955 \tTraining Loss: 0.029868 \tValidation Loss: 0.083044\n",
            "Epoch: 956 \tTraining Loss: 0.029863 \tValidation Loss: 0.083041\n",
            "Epoch: 957 \tTraining Loss: 0.029859 \tValidation Loss: 0.083038\n",
            "Epoch: 958 \tTraining Loss: 0.029854 \tValidation Loss: 0.083034\n",
            "Epoch: 959 \tTraining Loss: 0.029850 \tValidation Loss: 0.083031\n",
            "Epoch: 960 \tTraining Loss: 0.029846 \tValidation Loss: 0.083027\n",
            "Epoch: 961 \tTraining Loss: 0.029841 \tValidation Loss: 0.083024\n",
            "Epoch: 962 \tTraining Loss: 0.029837 \tValidation Loss: 0.083020\n",
            "Epoch: 963 \tTraining Loss: 0.029832 \tValidation Loss: 0.083016\n",
            "Epoch: 964 \tTraining Loss: 0.029828 \tValidation Loss: 0.083011\n",
            "Epoch: 965 \tTraining Loss: 0.029823 \tValidation Loss: 0.083007\n",
            "Epoch: 966 \tTraining Loss: 0.029819 \tValidation Loss: 0.083003\n",
            "Epoch: 967 \tTraining Loss: 0.029815 \tValidation Loss: 0.082999\n",
            "Epoch: 968 \tTraining Loss: 0.029810 \tValidation Loss: 0.082994\n",
            "Epoch: 969 \tTraining Loss: 0.029806 \tValidation Loss: 0.082989\n",
            "Epoch: 970 \tTraining Loss: 0.029801 \tValidation Loss: 0.082984\n",
            "Epoch: 971 \tTraining Loss: 0.029797 \tValidation Loss: 0.082979\n",
            "Epoch: 972 \tTraining Loss: 0.029792 \tValidation Loss: 0.082974\n",
            "Epoch: 973 \tTraining Loss: 0.029788 \tValidation Loss: 0.082968\n",
            "Epoch: 974 \tTraining Loss: 0.029784 \tValidation Loss: 0.082962\n",
            "Epoch: 975 \tTraining Loss: 0.029779 \tValidation Loss: 0.082956\n",
            "Epoch: 976 \tTraining Loss: 0.029775 \tValidation Loss: 0.082950\n",
            "Epoch: 977 \tTraining Loss: 0.029770 \tValidation Loss: 0.082944\n",
            "Epoch: 978 \tTraining Loss: 0.029766 \tValidation Loss: 0.082937\n",
            "Epoch: 979 \tTraining Loss: 0.029761 \tValidation Loss: 0.082930\n",
            "Epoch: 980 \tTraining Loss: 0.029757 \tValidation Loss: 0.082924\n",
            "Epoch: 981 \tTraining Loss: 0.029752 \tValidation Loss: 0.082916\n",
            "Epoch: 982 \tTraining Loss: 0.029748 \tValidation Loss: 0.082909\n",
            "Epoch: 983 \tTraining Loss: 0.029743 \tValidation Loss: 0.082901\n",
            "Epoch: 984 \tTraining Loss: 0.029739 \tValidation Loss: 0.082893\n",
            "Epoch: 985 \tTraining Loss: 0.029734 \tValidation Loss: 0.082885\n",
            "Epoch: 986 \tTraining Loss: 0.029730 \tValidation Loss: 0.082876\n",
            "Epoch: 987 \tTraining Loss: 0.029726 \tValidation Loss: 0.082867\n",
            "Epoch: 988 \tTraining Loss: 0.029721 \tValidation Loss: 0.082858\n",
            "Epoch: 989 \tTraining Loss: 0.029717 \tValidation Loss: 0.082849\n",
            "Epoch: 990 \tTraining Loss: 0.029712 \tValidation Loss: 0.082839\n",
            "Epoch: 991 \tTraining Loss: 0.029708 \tValidation Loss: 0.082830\n",
            "Epoch: 992 \tTraining Loss: 0.029703 \tValidation Loss: 0.082820\n",
            "Epoch: 993 \tTraining Loss: 0.029699 \tValidation Loss: 0.082810\n",
            "Epoch: 994 \tTraining Loss: 0.029694 \tValidation Loss: 0.082799\n",
            "Epoch: 995 \tTraining Loss: 0.029690 \tValidation Loss: 0.082788\n",
            "Epoch: 996 \tTraining Loss: 0.029685 \tValidation Loss: 0.082777\n",
            "Epoch: 997 \tTraining Loss: 0.029681 \tValidation Loss: 0.082765\n",
            "Epoch: 998 \tTraining Loss: 0.029676 \tValidation Loss: 0.082753\n",
            "Epoch: 999 \tTraining Loss: 0.029672 \tValidation Loss: 0.082741\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 1000\n",
        "train_model( model, optimizer, criterion, train_data, val_data, num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZeVo9TJ9dTk"
      },
      "source": [
        "Cargamos el mejor modelo obtenido del entrenamiento. \n",
        "*Observación:* En el entrenamiento se guarda un modelo en un archivo .pt usted puede descargar el archivo y guardarlo localmente. De esta forma, si quiere usar el modelo nuevamente sin volver a realizar entrenamiento, sólo carguelo como se indica en la siguiente celda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V35GtM169Wdd",
        "outputId": "4e5b2798-cfe7-46a9-8ee3-278b61a80351"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('model_bikeshare.pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yNPImH-9l3k"
      },
      "source": [
        "Visualizamos los parámetros del modelo obtenido anteriormente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5f-4tqI9ldc",
        "outputId": "643fc8ec-7ccd-4385-e8ec-46fd3c2ef2b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fc1.weight tensor([[-0.2909, -0.5202, -0.9124,  ..., -0.3929,  0.8624, -0.1233],\n",
            "        [-0.9005,  1.5120,  0.1287,  ..., -0.3618, -0.8718,  0.3783],\n",
            "        [-0.7015,  0.4838, -0.3770,  ..., -0.4471,  0.3842,  0.3364],\n",
            "        ...,\n",
            "        [ 0.3306,  1.9639,  1.6534,  ..., -1.0220,  0.0459,  0.4389],\n",
            "        [ 0.3883, -1.7634,  0.8740,  ..., -0.7139,  0.0360,  0.6779],\n",
            "        [-0.0090, -0.8017,  1.9312,  ..., -0.1891, -0.4169,  0.0750]])\n",
            "fc1.bias tensor([-1.4928, -2.1505, -1.8575, -1.3175, -1.6342, -0.1343, -1.8477, -2.7808,\n",
            "        -1.9228, -1.6656, -3.0133, -1.3412, -2.8331, -1.3237,  0.6343, -0.6796,\n",
            "        -0.4013, -2.1987, -2.1423, -1.9030, -2.0330, -3.7310, -1.4036, -3.8498,\n",
            "        -3.8249, -2.2780, -1.6138, -1.7221, -2.2921, -3.3429, -3.3940, -1.2424,\n",
            "        -1.3716, -0.9818, -2.7194, -2.5080, -2.4191, -2.5682])\n",
            "fc2.weight tensor([[-0.9975, -1.5561,  0.9406,  0.1738, -1.1389, -0.9854, -1.2554, -2.0273,\n",
            "         -1.2216,  1.4210,  2.1189,  0.2233, -1.4163, -0.5391, -0.9229, -0.9442,\n",
            "         -0.4599, -2.3765,  1.6088,  1.1768,  1.5813,  2.3703,  0.5969,  2.3594,\n",
            "         -1.8414,  1.6657, -0.9400,  1.1985,  0.9690,  2.1987, -3.7763,  1.0786,\n",
            "          0.8218, -1.1597,  1.5385,  1.3956,  1.4566, -1.6647]])\n",
            "fc2.bias tensor([1.1397])\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print (name, param.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4QIP9as9u7u"
      },
      "source": [
        "### Evaluación del modelo\n",
        "Ahora la prueba final con el test set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdELpZLp9uHp",
        "outputId": "7fba166b-1d99-49f0-b2a9-03320f8ac61d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.071458\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_loss=0.0\n",
        "\n",
        "criterion= nn.MSELoss()\n",
        "for data, target in test_data:\n",
        "  target = target.unsqueeze(1) #%\n",
        "  data, target =data.to(device), target.to(device) #%\n",
        "  output=model(data)\n",
        "  loss= criterion(output,target)\n",
        "  test_loss += loss.item()*data.size(0)\n",
        "test_loss = test_loss/len(test_data.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Se modifico el código anterior, específicamente en #%\n",
        "\n",
        "El código original tenía un problema porque la forma del tensor de objetivos \"target\" no era compatible con la forma de la salida del modelo, lo que podría causar problemas de tamaño y afectar negativamente al entrenamiento del modelo a largo plazo.\n",
        "\n",
        "La versión corregida del código resuelve este problema al agregar una operación de expansión de dimensión (mediante \"unsqueeze\") para el tensor de objetivos \"target\" antes de enviarlo al modelo. Esto se hace para asegurarse de que el tensor de objetivos tenga la misma forma que la salida del modelo, lo que permite calcular correctamente la pérdida utilizando el módulo de pérdida \"nn.MSELoss\".\n",
        "\n",
        "Además, también se ha optimizado el código para asignar los tensores \"data\" y \"target\" a la vez que se les aplica la función \"to(device)\" para enviarlos a la GPU. Esto reduce el número de líneas de código y lo hace más legible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fppYxUZAWq_"
      },
      "source": [
        "### Usando el modelo en contexto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmSC3s4J96RC"
      },
      "source": [
        "TO_DO 7: Finalmente, utilice el modelo encontrado para predecir el número de bicicletas rentadas en tres momentos (fecha, hora y demás atributos) diferentes que usted elija (pueden ser tomados del test set o con unos atributos nuevos que usted elija). \n",
        "Comente por favor lo siguiente: \n",
        "- Escribr si son atributos que usted seleccionó del dataset o unos nuevos.\n",
        "- Describa cómo obtuvo el valor de la predicción y qué valor dió (tenga en cuenta que la salida está normalizada, pero queremos la cantidad de bicicletas).\n",
        "- Si son atributos seleccionados del test set, compare su resultado con la etiqueta original. ¿Qué tal se desempeñó en esos tres casos?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "vYyGLkXw944m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    \n",
            "MSE: 0.04458500556243533    \n",
            "R^2: 0.9557199833683948\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "def get_prediction(values):\n",
        "    tensor = torch.tensor(values)\n",
        "    tensor = tensor.to(device)\n",
        "\n",
        "    output = model.forward(tensor)\n",
        "    probs = nn.functional.sigmoid(output)\n",
        "    conf, = torch.max(probs, 1)\n",
        "    return conf.item()\n",
        "\n",
        "def denormalize_cnt(values):\n",
        "    return np.float64(values) * original_data[\"cnt\"][\"std\"] + original_data[\"cnt\"][\"mean\"]\n",
        "\n",
        "def scatter_plot(x, y, labels: tuple[str, str]):\n",
        "    coef = np.polyfit(x, y, 1)\n",
        "    poly1d_fn = np.poly1d(coef)\n",
        "    plt.plot(x, y, \"yo\", x, poly1d_fn(x), \"--k\")\n",
        "    plt.xlabel(labels[0])\n",
        "    plt.ylabel(labels[1])\n",
        "\n",
        "\n",
        "pred_df = df[(df[\"yr\"] == 0) | ((df[\"mnth_11\"] == 0) & (df[\"mnth_12\"] == 0))]\n",
        "pred_dataset = MyDataset(pred_df, \"cnt\")\n",
        "pred_data = DataLoader(\n",
        "    pred_dataset,\n",
        "    batch_size=64,\n",
        ")\n",
        "\n",
        "\n",
        "real_labels = []\n",
        "predictions = []\n",
        "for i, (inputs, target) in enumerate(pred_data):\n",
        "    target = target.unsqueeze(1)\n",
        "    inputs, target = inputs.to(device), target.to(device)\n",
        "\n",
        "    output = model(inputs)\n",
        "    predictions.extend(output.tolist())\n",
        "    real_labels.extend(target.tolist())\n",
        "\n",
        "real_labels = np.array(real_labels).flatten()\n",
        "predictions = np.array(predictions).flatten()\n",
        "\n",
        "mse = mean_squared_error(real_labels, predictions)\n",
        "r2 = r2_score(real_labels, predictions)\n",
        "print(f\"\"\"\\\n",
        "    \\n\\rMSE: {mse}\\\n",
        "    \\n\\rR^2: {r2}\\\n",
        "\"\"\")\n",
        "\n",
        "cnt_predictions = denormalize_cnt(predictions).flatten()\n",
        "real_cnt = denormalize_cnt(real_labels).flatten()\n",
        "plt.subplots()\n",
        "scatter_plot(real_labels, predictions, (\"Real Data Normalized\", \"Predicted Data Normalized\"))\n",
        "plt.subplots()\n",
        "scatter_plot(real_cnt, cnt_predictions, (\"Real Data\", \"Predicted Data\"))\n",
        "\n",
        "# Mostrar la gráfica\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ¿Cómo fueron seleccionados los datos para predecir?\n",
        "Fueron datos seleccionados del dataset. Fueron justamente aquellos que no se involucraron en su entrenamiento ni en su validación; todos los anteriores a los 2 últimos meses. Es decir, toda la información con la cual el modelo no tuvo la más mínima evaluación o entrenamiento.\n",
        "\n",
        "### ¿Como se puede observar los valores predecidos del CNT?\n",
        "Para obtener el valor de la predicción de CNT, se guardaron los valores de normalización (media y std), lográndose luego denormalizar la data con estos. El único problema es que si existe una predicción multiplicada por la std menor a la media, entonces su valor será negativo y, por tanto, inconsistente.\n",
        "\n",
        "### ¿Cómo se desempeño?\n",
        "Su $R^2$ score fue de apróx. 96% y su MSE score de 4% comparando los valores verdaderos con los predecidos. Dado que es una data real en la cual el modelo nunca interactuó, podríamos decir que es muy bueno prediciendo la cantidad de bicicletas dado todos los demás valores."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
