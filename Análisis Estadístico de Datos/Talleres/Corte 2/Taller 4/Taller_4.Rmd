---
title: "Taller 4 AED"
author: "Dafne Castellanos, Diryon Mora, Fabio Rizo y Laura Gonzalez"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
```

## Primer punto

Un investigador considera tre índices para medir la severidad de los ataques al corazón. Los valores de esos índices para $n = 40$ pacientes con ataque al corazón que llegan a las emergencias de un hospital producen las siguientes estadísticas
resumidas:

$$
\begin{equation*}
\bar{X}
=
\begin{bmatrix}
46.1 \\
57.3 \\
50.4
\end{bmatrix}
\end{equation*}
$$

$$
\begin{equation*}
S
=
\begin{bmatrix}
101.3 & 63.0 & 71.0 \\
57.3 & 80.2 & 55.6 \\
50.4 & 55.6 & 97.4
\end{bmatrix}
\end{equation*}
$$

#### (a) Los tres índices son evaluados para cada paciente. Realice una prueba para la igualdad de las medias de los índices con $\alpha=0.05$.

```{r}
get_C = function(p) {
 C = diag(1, p - 1, p) - cbind(matrix(rep(0, p - 1)), diag(1, p - 1, p - 1))
 return(C)
}

T2 = function(x_bar, S, C, n) {
  C_x_bar = C %*% x_bar
  C_S_C_t = C %*% S %*% t(C)
  
  return(n * (t(C_x_bar) %*% solve(C_S_C_t) %*% C_x_bar))
}

Fish = function(n, p, alpha) {
  num = (n - 1) * (p - 1) 
  denom = (n - p + 1)
  return(num / denom * qf(1 - alpha, p - 1, n - p + 1))
}

T2.test = function(x_bar, S, C, n, p, alpha) {
  return (T2(x_bar, S, C, n) <= Fish(n, p, alpha)) 
}

p = 3;
n = 40;
x_bar = matrix(c(46.1, 57.3, 50.4))
S = matrix(c(101.3, 63, 71, 63, 80.2, 55.6, 71, 55.6, 97.4), ncol = p)

alpha = 0.05
C = get_C(p); C
T2(x_bar, S, C, n)
Fish(n, p, alpha)
T2.test(x_bar, S, C, n, p, alpha)
```

Debido a que el valor de $T^2$ supera su contraparte en la distribución de Fischer, se procede al rechazo de la hipótesis nula (H0). En otras palabras, se concluye que las medias de los tres pacientes no son iguales, considerando un nivel de significancia de 0.05.


#### (b) Juzgue las diferencias entre pares de las medias de los índices usando intervalos de confianza $(T^2)$ simultáneos del 95 %.

```{r}
get_C = function(p) {
  C = diag(p) - cbind(matrix(rep(0, p)), diag(1, p, p - 1));
  C[p, 1] = 1
  C[p, p] = -1
  return (matrix(C, nrow = p, ncol = p))
}


simultaneous_ci = function(x_bar, S, C, n, p, alpha) {
  left = t(C) %*% x_bar;
  right = sqrt(Fish(n, p, alpha)) * sqrt((t(C) %*% S %*% C) / n)
  
  return(c(left + right, left - right))
}

C = get_C(p)
sim_intervals = matrix(0, ncol = p, nrow = 2);
for (i in 1:p) {
  c = C[i, ];
  sim_intervals[, i] = simultaneous_ci(x_bar, S, c, n, p, alpha)
}

sim_intervals
```
Se tienen los intervalos:

$$
\mu_1-\mu_2:[-14.239955, -8.160045]
$$
$$
\mu_2-\mu_3:[3.5749 , 10.2251 ]
$$
$$
\mu_1-\mu_3:[-7.372644, -1.227356]
$$

## Punto 2

Observaciones sobre dos respuestas fueron coleccionadas para dos tratamientos Las observaciones vectoriales [x1, x2]′ fueron:

$$
\begin{equation*}
Tratamiento\_2
=
\begin{bmatrix}
3 \\
3
\end{bmatrix}
,
\begin{bmatrix}
1 \\
6
\end{bmatrix}
,
\begin{bmatrix}
2 \\
3
\end{bmatrix}
\end{equation*}
$$

$$
\begin{equation*}
Tratamiento\_3
=
\begin{bmatrix}
2 \\
3
\end{bmatrix}
,
\begin{bmatrix}
5 \\
1
\end{bmatrix}
,
\begin{bmatrix}
3 \\
1
\end{bmatrix}
,
\begin{bmatrix}
2 \\
3
\end{bmatrix}
\end{equation*}
$$

#### (a) Calcule $S_{pooled}$

```{r}
n1 = 3;
n2 = 4;
p = 2;
T2 = matrix(c(3, 1, 2, 3, 6, 3), nrow = n1, ncol =p);
T3 = matrix(c(2, 5, 3, 2, 3, 1, 1, 3), nrow=n2, ncol=p);

x_bar1 = colMeans(T2); 
x_bar2 = colMeans(T3); 

S1 = cov(T2);
S2 = cov(T3);

spooled = function(n1, n2, S1, S2) {
  return((n1 - 1) / (n1 + n2 - 2) * S1 + (n2 - 1) / (n1 + n2 - 2) * S2)
}

S_spool = spooled(n1, n2, S1, S2);S_spool
```

#### (b) Realice la prueba $H_0 : \mu_2 - \mu_3 = 0$ usando un enfoque de dos muestras con $\alpha = 0.01$.

```{r}
get_T2 = function(n1, n2, x_bar1, x_bar2, S1, S2) {
  x_bar_diff = x_bar1 - x_bar2;
  
  inv_S = solve((1 / n1 + 1 / n2) * spooled(n1, n2, S1, S2))
  
  return(as.numeric(t(x_bar_diff) %*% inv_S %*% x_bar_diff))
}

get_C2 = function(n1, n2, p, alpha) {
  return(((n1 + n2 - 2) * p / (n1 + n2 - p - 1) ) * qf(1 - alpha, p, n1 + n2 - p - 1))
}

get_T2(n1, n2, x_bar1, x_bar2, S1, S2)

alpha = 0.01
get_C2(n1, n2, p, alpha);

test_T2 = function(n1, n2, p, x_bar1, x_bar2, S1, S2, alpha) {
  return(get_T2(n1, n2, x_bar1, x_bar2, S1, S2) > get_C2(n1, n2, p, alpha)) # Si es TRUE, se rechaza H0
}

test_T2(n1, n2, p, x_bar1, x_bar2, S1, S2, alpha)
```

Dado que el valor de T2 no supera el valor crítico de c2, no se cuenta con suficiente evidencia estadística para rechazar la hipótesis nula (H0), la cual establece que la diferencia entre las medias de los grupos u2 y u3 es igual a cero $H_o:\mu_2-\mu_3=0$. Este resultado se obtiene al considerar un nivel de significancia de 0.01.

#### (c) Construya un intervalo de confianza simultáneo $(T^2)$ del 99% para las diferencias $\mu_{2i} − \mu_{3i}$, $i = 1, 2$.

```{r}
get_T2_intervals = function(a, n1, n2, p, x_bar1, x_bar2, S1, S2, alpha) {
  C = sqrt(get_C2(n1, n2, p, alpha))
  
  left = t(a) %*% (x_bar1 - x_bar2)
  right = C * sqrt(t(a) %*% ((1/n1 + 1/n2) * spooled(n1, n2, S1, S2)) %*% a)
  return(matrix(c(left + right, left - right)))
}

A = matrix(c(1, 0, 0, 1), nrow = 2, ncol = 2);
alpha = 0.01
T2_intervals = matrix(0, nrow = 2, ncol = 2)
for (i in 1:nrow(A)) {
  a = A[i, ]
  T2_intervals[, i] = get_T2_intervals(a, n1, n2, p, x_bar1, x_bar2, S1, S2, alpha)
}
T2_intervals
```

En otras palabras, se tiene que:

$$
\mu_{21}-\mu_{31}:[-7.480741, 5.480741]
$$
$$
\mu_{21}-\mu_{31}:[-5.245688, 9.245688]
$$

## Punto 3

Dado los datos:

$$
\begin{matrix}
z_1     & 10 & 5 & 7 & 19 & 11 & 18 \\
z_2     & 2 & 3 & 3 & 6 & 7 & 9 \\ \hline
y       & 15 & 9 & 3 & 25 & 7 & 13
\end{matrix}
$$

#### (a) Ajuste el modelo de regresión lineal $Y_j=\beta_0+\beta_1z_{j1}+\beta_2z_{j2}+\epsilon_j$, j=1,2,..,6.

```{r}
z1 = matrix(c(10, 5, 7, 19, 11, 18));
z2 = matrix(c(2, 3, 3, 6, 7, 9));
y = matrix(c(15, 9, 3, 25, 7, 13));

data = data.frame(z1, z2, y)
model = lm(y ~ z1 + z2, data = data)

coefs = coef(model); coefs
```

Así tenemos que:

$$
\hat{y}=2.147976    + 1.782316   z_1 - 2.188333 z_2
$$

#### (b) Determine los intervalos de confianza del 95% simultáneos (uno a la vez) para $\beta_1$ y $\beta_2$.

```{r}
alpha = 0.05
si_beta1 = confint(model, level = 1 - alpha, parm=c(2)); si_beta1
si_beta2 = confint(model, level = 1 - alpha, parm=c(3)); si_beta2
```
Note que:

$$
\beta_1:[0.1968411,3.367791] \\
\beta_2:[-5.475374 ,1.098707]
$$

Se observa que el coeficiente $\beta_2$ en el modelo de regresión lineal incluye el valor 0. Esto sugiere que la variable $z_2$ no está haciendo una contribución significativa en la explicación de la variable de respuesta en el modelo. En este caso, se puede considerar eliminar la variable $z_2$ del modelo y realizar un análisis de regresión solo con la variable $z_1$.

#### (c) Comprueba la prueba de hipótesis nula de que sólo el coeficiente $\beta_1$ es cero.

```{r}
beta1_index = 2
p_value = summary(model)$coefficients[beta1_index, 4]; p_value
alpha = 0.05

p_value > alpha # Si es FALSE, se puede rechazar H0 (que beta1 es 0)
```

Al realizar la prueba de hipótesis, se rechaza la hipótesis nula H0, esto indica que el coeficiente $\beta_1$ en el modelo de regresión lineal no es igual a cero y es estadísticamente significativo. 

#### (d) Determine el valor esperado de la predicción $(E(Y))$ para $z_1=6$ y $z_2=4$. Calcule su intervalo de confianza del 95% correspondiente (el del valor esperado).

```{r}
newdata = data.frame(z1 = 6, z2 = 4);
expected_value2=coefs[1]+(coefs[2]*6)+(coefs[3]*4); expected_value2
intervals = predict(model, newdata, interval = "confidence", level = 0.95)[2:3]; intervals
```

Note que el valor esperado de la predicción para $z_1=6$ y $z_2=4$ es $(E(Y))=4.088541$. Donde el intervalo de confianza del 95% es $[-4.705851,12.882934]$.

#### (e) Determine el intervalo de confianza del 95% para la predicción $(Y)$ cuando $z_1=6$ y $z_2=4$.

```{r}
pred_intervals = predict(model, newdata, interval = "prediction", level = 0.95)[2:3]
pred_intervals
```

Se tiene el intervalo: $[-11.96283,20.13991]$

## Punto 4

La librería **MASS** (carguela con library(MASS)) contiene el dataset de Boston, el cual registró la variable medv (valor medio de una casa) para 506 barrios en Boston. En este ejercicio, se buscará predecir la variable **medv** usando 13 predictores tales como: **rm** (número promedio de habitaciones por casa), **age** (promedio de la edad de las casas), y **lstat** (porcentaje de hogares con bajo nivel socioeconómico). Para este ejercicio puede usar la función **lm** de R.

#### (a) Realice el ajuste de regresión lineal simple usando como variable independiente **lstat**. Realice un resumen de los resultados (use la función summary). ¿Es la pendiente (coeficiente asociado a **lstat**) cero? Justifique estadísticamente su respuesta.

```{r}
model = lm(medv ~ lstat, data = Boston)
summary(model)
```

Note que la pendiente es -0.95005 aproximadamente, valor cercano a cero, pero no es cero. Podemos justificar estadísticamente esta respuesta mediante la prueba de hipótesis de dos colas, donde la hipótesis nula es que la pendiente es igual a cero y la hipótesis alternativa es que la pendiente es diferente de cero.

En este caso, el valor del estadístico t es de -24.53, con un valor de p-valor menor que 2.2e-16, lo que indica que hay una relación significativa entre las variables medv y lstat. Por lo tanto, podemos rechazar la hipótesis nula de que la pendiente es cero y concluir que existe una relación significativa entre estas dos variables.

#### (b) Determine el intervalo de confianza del 95% para los coeficientes (use la función confint())

```{r}
confint(model, level = 0.95)
```
El intervalo de confianza del 95% para el intercepto es de $(33.448457, 35.6592247)$ y el intervalo de confianza del 95% para la pendiente (coeficiente asociado a lstat) es de $(-1.026148, -0.8739505)$. 

#### (c) Realice las predicciones para el valor esperado de **medv** y los correspondientes intervalos de confianza del 95% para los valores de lstat=c(5,10,15). Sugerencia: use **predict()**. Determine el intervalo de confianza para la predicción (no el valor esperado).

```{r}
newdata = data.frame(lstat = c(5, 10, 15))
newdata$medv = predict(model, newdata); newdata

newmodel = lm(medv ~ lstat, data = newdata)
confint(newmodel, level = 0.95)
```

```{r}
newdata <- data.frame(lstat = c(5, 10, 15))
pred <- predict(model, newdata, interval = "confidence")
cbind(newdata, pred)
```


Esto indica que para un valor de lstat=5, el valor esperado de medv es de aproximadamente 29.80359ne y el intervalo de confianza del 95% para la predicción es de (, ). De manera similar, para un valor de lstat=10, el valor esperado de medv es de aproximadamente 25.05335 y el intervalo de confianza del 95% para la predicción es de (, ), y para un valor de lstat=15, el valor esperado de medv es de aproximadamente 20.30310 y el intervalo de confianza del 95% para la predicción es de (, ).

#### (d) Grafique el diagrama de dispersión de **medv** y **lstat** y la recta de regresión (use abline).

```{r}
plot(medv ~ lstat, data = Boston)
abline(model)
```

#### (e) Realice la regresión lineal de *medv** utilizando todas las variables independientes. Determine los intervalos de confianza del 95% de los coeficientes asociados a las variables independientes.

```{r}
model = lm(medv ~ ., data = Boston)
confint(model, level = 0.95)
```

#### (f) Con el modelo anterior (e) determine el intervalo de confianza del 95% del valor esperado de *medv** para el valor promedio de las variables independientes. Ahora, determine el intervalo de confianza del 95% para la predicción usando el mismo vector de entrada.

```{r}
newdata = colMeans(Boston[, names(Boston) != "medv"])
newdata = data.frame(as.list(newdata))
intervals = predict(model, newdata, interval = "confidence", level = 0.95); intervals
pred_intervals = predict(model, newdata, interval = "prediction", level = 0.95); pred_intervals
```
Note que el primer valor mostrará el valor esperado de medv y el intervalo de confianza del 95% para ese valor: $[22.11832 , 22.94729]$. El segundo valor mostrará el intervalo de confianza del 95% para la predicción de medv: $[13.20005,31.86556]$.

Observe que el intervalo de confianza del 95% para la predicción es más amplio que el intervalo de confianza del 95% del valor esperado de medv. Esto se debe a que el intervalo de confianza para la predicción también tiene en cuenta la variabilidad del error aleatorio.

## Punto 5

Se realizan observaciones de dos respuestas sobre tres tratamientos. Los vectores de observación  [x1, x2]′ son:

$$
\begin{equation*}
Tratamiento\_1
=
\begin{bmatrix}
2 \\
9
\end{bmatrix}
,
\begin{bmatrix}
3 \\
2
\end{bmatrix}
,
\begin{bmatrix}
7 \\
5
\end{bmatrix}
,
\begin{bmatrix}
2 \\
1
\end{bmatrix}
,
\begin{bmatrix}
7 \\
5
\end{bmatrix}
\end{equation*}
$$

$$
\begin{equation*}
Tratamiento\_2
=
\begin{bmatrix}
3 \\
2
\end{bmatrix}
,
\begin{bmatrix}
2 \\
4
\end{bmatrix}
,
\begin{bmatrix}
9 \\
4
\end{bmatrix}
\end{equation*}
$$

$$
\begin{equation*}
Tratamiento\_3
=
\begin{bmatrix}
1 \\
4
\end{bmatrix}
,
\begin{bmatrix}
7 \\
2
\end{bmatrix}
,
\begin{bmatrix}
4 \\
9
\end{bmatrix}
,
\begin{bmatrix}
3 \\
2
\end{bmatrix}
\end{equation*}
$$
#### (a) Construya la tabla de one-way MANOVA.

```{r}
n1 = 5;
n2 = 3;
n3 = 4;
p = 2;
T1 = matrix(c(2, 3, 7, 2, 7, 9, 2, 5, 1, 5), ncol = p, nrow = n1);
T2 = matrix(c(3, 2, 9, 2, 4, 4), ncol = p, nrow = n2);
T3 = matrix(c(1, 7, 4, 3, 4, 2, 9, 2), ncol = p, nrow = n3);


data = data.frame(group=rep(c("T1", "T2", "T3"), times=c(n1,n2,n3)),
                   x1=c(T1[,1], T2[,1], T3[,1]), 
                   x2=c(T1[,2], T2[,2], T3[,2]))

get_B = function(model) {
  return(summary(model)$SS$group)
}

get_W = function(model) {
  return(summary(model)$SS$Residuals)
}

model = manova(cbind(x1,x2) ~ group,data=data)

B = get_B(model);
W = get_W(model);

oneway_manova_table = B + W; oneway_manova_table
```

#### (b) Evalue el Lambda de Wilk , Λ∗, y realice una prueba de hipótesis sobre los efectos de tratamientos. Set α = 0.05.

```{r}
wilks = data.frame(as.list(summary(model, test="Wilks")$stats[1,]))$Wilks;
wilks
wilks_test = function(model, alpha) {
  stats = data.frame(as.list(summary(model, test="Wilks")$stats[1,]));
  num_df = stats$num.Df
  den_df = stats$den.Df
  
  approx_f = stats$approx.F
  f = qf(1 - alpha, num_df, den_df)
  
  return(approx_f > f) # Si es TRUE, se rechaza H0
}

alpha = 0.05
wilks_test(model, alpha)
```

En el punto B, Al utilizar los valores de tratamientos del problema, vemos que no tenemos suficiente evidencia para rechazar H0.

#### (c) Repita la prueba considerando que la muestra es grande.

```{r}
alpha = 0.05
g = 3

muestra = 100;
num_df = 2 * p;
den_df = 2 * (muestra - p - 2);

approx_f = (1 - sqrt(wilks)) / sqrt(wilks) * (muestra - g - 1) / (g - 1);
f = qf(1 - alpha, num_df, den_df);

print(approx_f)
print(f)
approx_f > f

```

 Lo mismo ocurre al considerar una muestra grande en el punto c.
